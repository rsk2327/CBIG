{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback import *\n",
    "from fastai.basic_train import *\n",
    "import torchvision.models as tmodels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from scipy.misc import imsave\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/santhosr/Documents/Birad/FastAI/RaceClassification/' )\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from birad import *\n",
    "from birad import setTruthFile, getRaceLabel\n",
    "\n",
    "\n",
    "inputFolder1 = '/home/santhosr/Documents/Birad/ProcessedData/FullRes'\n",
    "truthFile1 = '/home/santhosr/Documents/Birad/birad_targetFile.csv'\n",
    "\n",
    "inputFolder2 = '/home/santhosr/Documents/Birad/ProcessedData/PennExtra_3500/'\n",
    "truthFile2 = '/home/santhosr/Documents/Birad/RaceDL_ExtraCaucasian.csv'\n",
    "\n",
    "df1 = pd.read_csv('/home/santhosr/Documents/Birad/birad_targetFile.csv')\n",
    "df1.drop(['PresIntentType','DBT'],inplace = True,axis=1)\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('/home/santhosr/Documents/Birad/RaceDL_ExtraCaucasian.csv')\n",
    "df2.Medview_Race = 'White'\n",
    "truth = pd.concat([df1,df2],sort=True)\n",
    "\n",
    "setTruthFile(truth)\n",
    "\n",
    "dfFile = \"/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/DataFile10.csv\"\n",
    "\n",
    "modelName = 'model_resnet50_id10_acc833_loss386'\n",
    "\n",
    "\n",
    "#Feature Directories\n",
    "trainFolder = '/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/Features/model9_2/train'\n",
    "\n",
    "validFolder = '/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/Features/model9_2/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dfFile)\n",
    "\n",
    "d = pd.concat([df[df.train==True].iloc[0:100], df[df.train==False].iloc[0:100], ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75048084</td>\n",
       "      <td>FullRes/2/75048084_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>76876308</td>\n",
       "      <td>FullRes/2/76876308_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>76750724</td>\n",
       "      <td>PennExtra_3500/76750724_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>76809071</td>\n",
       "      <td>FullRes/1/76809071_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>75352509</td>\n",
       "      <td>FullRes/2/75352509_L_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>75225607</td>\n",
       "      <td>FullRes/2/75225607_L_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>75821525</td>\n",
       "      <td>FullRes/3/75821525_L_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3027487</td>\n",
       "      <td>FullRes/3/3027487_L_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>76779721</td>\n",
       "      <td>FullRes/2/76779721_L_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>75476406</td>\n",
       "      <td>PennExtra_3500/75476406_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4251475</td>\n",
       "      <td>FullRes/2/4251475_L_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4016060</td>\n",
       "      <td>PennExtra_3500/4016060_FOR-PROCESSING_L_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>76812365</td>\n",
       "      <td>FullRes/2/76812365_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>75693890</td>\n",
       "      <td>PennExtra_3500/75693890_FOR-PROCESSING_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>75720669</td>\n",
       "      <td>FullRes/2/75720669_L_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>76160416</td>\n",
       "      <td>PennExtra_3500/76160416_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>76907726</td>\n",
       "      <td>FullRes/2/76907726_L_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5229987</td>\n",
       "      <td>PennExtra_3500/5229987_FOR-PROCESSING_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>75077193</td>\n",
       "      <td>FullRes/2/75077193_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>76992155</td>\n",
       "      <td>FullRes/3/76992155_L_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>76198308</td>\n",
       "      <td>FullRes/3/76198308_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5157270</td>\n",
       "      <td>FullRes/3/5157270_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>75519299</td>\n",
       "      <td>PennExtra_3500/75519299_FOR-PROCESSING_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>4915676</td>\n",
       "      <td>FullRes/2/4915676_L_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>75481927</td>\n",
       "      <td>FullRes/1/75481927_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>76861174</td>\n",
       "      <td>FullRes/2/76861174_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>75758196</td>\n",
       "      <td>FullRes/1/75758196_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>75983697</td>\n",
       "      <td>PennExtra_3500/75983697_FOR-PROCESSING_R_MLO_1...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>75484108</td>\n",
       "      <td>PennExtra_3500/75484108_FOR-PROCESSING_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>5306646</td>\n",
       "      <td>FullRes/1/5306646_L_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>76710916</td>\n",
       "      <td>FullRes/3/76710916_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>76330751</td>\n",
       "      <td>FullRes/2/76330751_L_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>76996674</td>\n",
       "      <td>PennExtra_3500/76996674_FOR-PROCESSING_R_MLO_1...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>76071090</td>\n",
       "      <td>FullRes/2/76071090_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>76075934</td>\n",
       "      <td>PennExtra_3500/76075934_FOR-PROCESSING_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4788877</td>\n",
       "      <td>FullRes/2/4788877_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>76406634</td>\n",
       "      <td>PennExtra_3500/76406634_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4392440</td>\n",
       "      <td>FullRes/2/4392440_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5245879</td>\n",
       "      <td>FullRes/1/5245879_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>75712461</td>\n",
       "      <td>FullRes/3/75712461_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>76759516</td>\n",
       "      <td>FullRes/2/76759516_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>76642496</td>\n",
       "      <td>FullRes/3/76642496_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>75538135</td>\n",
       "      <td>PennExtra_3500/75538135_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>75233854</td>\n",
       "      <td>FullRes/2/75233854_L_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>75130796</td>\n",
       "      <td>PennExtra_3500/75130796_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>75089221</td>\n",
       "      <td>FullRes/2/75089221_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>4289935</td>\n",
       "      <td>FullRes/2/4289935_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>76947686</td>\n",
       "      <td>PennExtra_3500/76947686_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>75384640</td>\n",
       "      <td>FullRes/2/75384640_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>75251215</td>\n",
       "      <td>FullRes/2/75251215_L_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3837223</td>\n",
       "      <td>FullRes/3/3837223_L_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>76466209</td>\n",
       "      <td>PennExtra_3500/76466209_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>75928606</td>\n",
       "      <td>FullRes/3/75928606_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4731830</td>\n",
       "      <td>PennExtra_3500/4731830_FOR-PROCESSING_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>75593531</td>\n",
       "      <td>FullRes/3/75593531_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>75951552</td>\n",
       "      <td>FullRes/2/75951552_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3475987</td>\n",
       "      <td>FullRes/3/3475987_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>4630654</td>\n",
       "      <td>FullRes/2/4630654_L_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4981491</td>\n",
       "      <td>FullRes/3/4981491_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>76105288</td>\n",
       "      <td>FullRes/3/76105288_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DummyID                                           filename  train\n",
       "5    75048084                      FullRes/2/75048084_R_CC_1.jpg   True\n",
       "14   76876308                     FullRes/2/76876308_R_MLO_1.jpg   True\n",
       "18   76750724  PennExtra_3500/76750724_FOR-PROCESSING_L_CC_1.jpg   True\n",
       "37   76809071                      FullRes/1/76809071_R_CC_1.jpg   True\n",
       "50   75352509                     FullRes/2/75352509_L_MLO_1.jpg   True\n",
       "51   75225607                      FullRes/2/75225607_L_CC_1.jpg   True\n",
       "56   75821525                      FullRes/3/75821525_L_CC_1.jpg   True\n",
       "58    3027487                      FullRes/3/3027487_L_MLO_1.jpg   True\n",
       "59   76779721                      FullRes/2/76779721_L_CC_1.jpg   True\n",
       "64   75476406  PennExtra_3500/75476406_FOR-PROCESSING_L_CC_1.jpg   True\n",
       "69    4251475                       FullRes/2/4251475_L_CC_1.jpg   True\n",
       "70    4016060  PennExtra_3500/4016060_FOR-PROCESSING_L_MLO_1.jpg   True\n",
       "81   76812365                      FullRes/2/76812365_R_CC_1.jpg   True\n",
       "82   75693890  PennExtra_3500/75693890_FOR-PROCESSING_R_CC_1.jpg   True\n",
       "86   75720669                      FullRes/2/75720669_L_CC_1.jpg   True\n",
       "90   76160416  PennExtra_3500/76160416_FOR-PROCESSING_L_CC_1.jpg   True\n",
       "114  76907726                     FullRes/2/76907726_L_MLO_1.jpg   True\n",
       "117   5229987  PennExtra_3500/5229987_FOR-PROCESSING_R_MLO_1.jpg   True\n",
       "119  75077193                      FullRes/2/75077193_R_CC_1.jpg   True\n",
       "129  76992155                     FullRes/3/76992155_L_MLO_1.jpg   True\n",
       "134  76198308                     FullRes/3/76198308_R_MLO_1.jpg   True\n",
       "141   5157270                       FullRes/3/5157270_R_CC_1.jpg   True\n",
       "154  75519299  PennExtra_3500/75519299_FOR-PROCESSING_R_CC_1.jpg   True\n",
       "156   4915676                      FullRes/2/4915676_L_MLO_1.jpg   True\n",
       "158  75481927                     FullRes/1/75481927_R_MLO_1.jpg   True\n",
       "175  76861174                     FullRes/2/76861174_R_MLO_1.jpg   True\n",
       "178  75758196                     FullRes/1/75758196_R_MLO_1.jpg   True\n",
       "192  75983697  PennExtra_3500/75983697_FOR-PROCESSING_R_MLO_1...   True\n",
       "194  75484108  PennExtra_3500/75484108_FOR-PROCESSING_R_CC_1.jpg   True\n",
       "204   5306646                       FullRes/1/5306646_L_CC_1.jpg   True\n",
       "..        ...                                                ...    ...\n",
       "84   76710916                     FullRes/3/76710916_R_MLO_1.jpg  False\n",
       "85   76330751                     FullRes/2/76330751_L_MLO_1.jpg  False\n",
       "87   76996674  PennExtra_3500/76996674_FOR-PROCESSING_R_MLO_1...  False\n",
       "88   76071090                     FullRes/2/76071090_R_MLO_1.jpg  False\n",
       "89   76075934  PennExtra_3500/76075934_FOR-PROCESSING_R_CC_1.jpg  False\n",
       "91    4788877                       FullRes/2/4788877_R_CC_1.jpg  False\n",
       "92   76406634  PennExtra_3500/76406634_FOR-PROCESSING_L_CC_1.jpg  False\n",
       "93    4392440                       FullRes/2/4392440_R_CC_1.jpg  False\n",
       "94    5245879                       FullRes/1/5245879_L_CC_1.jpg  False\n",
       "95   75712461                     FullRes/3/75712461_R_MLO_1.jpg  False\n",
       "96   76759516                      FullRes/2/76759516_L_CC_1.jpg  False\n",
       "97   76642496                     FullRes/3/76642496_R_MLO_1.jpg  False\n",
       "98   75538135  PennExtra_3500/75538135_FOR-PROCESSING_L_CC_1.jpg  False\n",
       "99   75233854                     FullRes/2/75233854_L_MLO_1.jpg  False\n",
       "100  75130796  PennExtra_3500/75130796_FOR-PROCESSING_L_CC_1.jpg  False\n",
       "101  75089221                      FullRes/2/75089221_R_CC_1.jpg  False\n",
       "102   4289935                      FullRes/2/4289935_R_MLO_1.jpg  False\n",
       "103  76947686  PennExtra_3500/76947686_FOR-PROCESSING_L_CC_1.jpg  False\n",
       "104  75384640                      FullRes/2/75384640_R_CC_1.jpg  False\n",
       "105  75251215                     FullRes/2/75251215_L_MLO_1.jpg  False\n",
       "106   3837223                      FullRes/3/3837223_L_MLO_1.jpg  False\n",
       "107  76466209  PennExtra_3500/76466209_FOR-PROCESSING_L_CC_1.jpg  False\n",
       "108  75928606                      FullRes/3/75928606_R_CC_1.jpg  False\n",
       "109   4731830  PennExtra_3500/4731830_FOR-PROCESSING_R_MLO_1.jpg  False\n",
       "110  75593531                      FullRes/3/75593531_L_CC_1.jpg  False\n",
       "111  75951552                      FullRes/2/75951552_L_CC_1.jpg  False\n",
       "112   3475987                      FullRes/3/3475987_R_MLO_1.jpg  False\n",
       "113   4630654                      FullRes/2/4630654_L_MLO_1.jpg  False\n",
       "115   4981491                       FullRes/3/4981491_R_CC_1.jpg  False\n",
       "116  76105288                      FullRes/3/76105288_R_CC_1.jpg  False\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can deactivate this warning by passing `no_check=True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py:205: UserWarning: There seems to be something wrong with your dataset, can't access self.train_ds[i] for all i in [33, 56, 40, 22, 5, 90, 60, 92, 81, 0, 32, 57, 70, 78, 36, 9, 68, 61, 46, 82, 63, 45, 15, 62, 75, 26, 86, 74, 23, 93, 20, 30, 99, 1, 21, 79, 72, 16, 71, 50, 77, 13, 29, 48, 38, 69, 43, 76, 8, 73]\n",
      "  warn(f\"There seems to be something wrong with your dataset, can't access self.train_ds[i] for all i in {idx}\")\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 3772) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 3772) is killed by signal: Segmentation fault. ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d1c3d2196326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Creates the FastAI Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageItemList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/santhosr/Documents/Birad/ProcessedData/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_from_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetRaceLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(self, stats, do_x, do_y)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;34m\"Add normalize transform using `stats` (defaults to `DataBunch.batch_stats`)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'norm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Can not call normalize twice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/data.py\u001b[0m in \u001b[0;36mbatch_stats\u001b[0;34m(self, funcs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;34m\"Grab a batch of data and call reduction function `func` per channel\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mfuncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, ds_type, detach, denorm, cpu)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 3772) exited unexpectedly"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/home/santhosr/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "#Creates the FastAI Dataset\n",
    "data = ImageItemList.from_df(df=d,path='/home/santhosr/Documents/Birad/ProcessedData/', cols='filename').split_from_df(col='train').label_from_func(getRaceLabel).transform(get_transforms(),size=256).databunch(bs=50).normalize()\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (100 items)\n",
       "[Category 0, Category 1, Category 0, Category 1, Category 0]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData\n",
       "x: ImageItemList (100 items)\n",
       "[Image (3, 3328, 2560), Image (3, 4096, 3328), Image (3, 4096, 3328), Image (3, 3328, 2560), Image (3, 3328, 2560)]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (100 items)\n",
       "[Category 1, Category 1, Category 1, Category 0, Category 0]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData\n",
       "x: ImageItemList (100 items)\n",
       "[Image (3, 4096, 3328), Image (3, 4096, 3328), Image (3, 3328, 2560), Image (3, 4096, 3328), Image (3, 3328, 2560)]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData;\n",
       "\n",
       "Test: None, model=Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Lambda()\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f7b47b2c630>, metrics=[<function accuracy at 0x7f7b4bd3fd90>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/santhosr/Documents/Birad/ProcessedData'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU(inplace)\n",
       "  (11): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace)\n",
       "  (20): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (24): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU(inplace)\n",
       "  (27): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (30): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (31): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (33): ReLU(inplace)\n",
       "  (34): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (38): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (40): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (42): ReLU(inplace)\n",
       "  (43): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (44): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (45): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (46): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (47): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (49): ReLU(inplace)\n",
       "  (50): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (51): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (52): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (54): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (56): ReLU(inplace)\n",
       "), Sequential(\n",
       "  (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (14): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): ReLU(inplace)\n",
       "  (16): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): ReLU(inplace)\n",
       "  (23): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (27): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): ReLU(inplace)\n",
       "  (30): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (34): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (35): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): ReLU(inplace)\n",
       "  (37): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (39): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (40): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (41): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (42): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (43): ReLU(inplace)\n",
       "  (44): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (48): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (50): ReLU(inplace)\n",
       "  (51): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (52): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (53): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (55): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (56): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (57): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (58): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (59): ReLU(inplace)\n",
       "  (60): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (62): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (64): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (66): ReLU(inplace)\n",
       "), Sequential(\n",
       "  (0): AdaptiveAvgPool2d(output_size=1)\n",
       "  (1): AdaptiveMaxPool2d(output_size=1)\n",
       "  (2): Lambda()\n",
       "  (3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Dropout(p=0.25)\n",
       "  (5): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Dropout(p=0.5)\n",
       "  (9): Linear(in_features=512, out_features=2, bias=True)\n",
       ")])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates the model architecture \n",
    "learn = create_cnn(data, tmodels.resnet50, metrics=accuracy,pretrained=True)\n",
    "\n",
    "learn.load('/home/santhosr/Documents/Birad/ProcessedData/models/'+modelName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.weight\n",
      "0.1.weight\n",
      "0.1.bias\n",
      "0.4.0.conv1.weight\n",
      "0.4.0.bn1.weight\n",
      "0.4.0.bn1.bias\n",
      "0.4.0.conv2.weight\n",
      "0.4.0.bn2.weight\n",
      "0.4.0.bn2.bias\n",
      "0.4.0.conv3.weight\n",
      "0.4.0.bn3.weight\n",
      "0.4.0.bn3.bias\n",
      "0.4.0.downsample.0.weight\n",
      "0.4.0.downsample.1.weight\n",
      "0.4.0.downsample.1.bias\n",
      "0.4.1.conv1.weight\n",
      "0.4.1.bn1.weight\n",
      "0.4.1.bn1.bias\n",
      "0.4.1.conv2.weight\n",
      "0.4.1.bn2.weight\n",
      "0.4.1.bn2.bias\n",
      "0.4.1.conv3.weight\n",
      "0.4.1.bn3.weight\n",
      "0.4.1.bn3.bias\n",
      "0.4.2.conv1.weight\n",
      "0.4.2.bn1.weight\n",
      "0.4.2.bn1.bias\n",
      "0.4.2.conv2.weight\n",
      "0.4.2.bn2.weight\n",
      "0.4.2.bn2.bias\n",
      "0.4.2.conv3.weight\n",
      "0.4.2.bn3.weight\n",
      "0.4.2.bn3.bias\n",
      "0.5.0.conv1.weight\n",
      "0.5.0.bn1.weight\n",
      "0.5.0.bn1.bias\n",
      "0.5.0.conv2.weight\n",
      "0.5.0.bn2.weight\n",
      "0.5.0.bn2.bias\n",
      "0.5.0.conv3.weight\n",
      "0.5.0.bn3.weight\n",
      "0.5.0.bn3.bias\n",
      "0.5.0.downsample.0.weight\n",
      "0.5.0.downsample.1.weight\n",
      "0.5.0.downsample.1.bias\n",
      "0.5.1.conv1.weight\n",
      "0.5.1.bn1.weight\n",
      "0.5.1.bn1.bias\n",
      "0.5.1.conv2.weight\n",
      "0.5.1.bn2.weight\n",
      "0.5.1.bn2.bias\n",
      "0.5.1.conv3.weight\n",
      "0.5.1.bn3.weight\n",
      "0.5.1.bn3.bias\n",
      "0.5.2.conv1.weight\n",
      "0.5.2.bn1.weight\n",
      "0.5.2.bn1.bias\n",
      "0.5.2.conv2.weight\n",
      "0.5.2.bn2.weight\n",
      "0.5.2.bn2.bias\n",
      "0.5.2.conv3.weight\n",
      "0.5.2.bn3.weight\n",
      "0.5.2.bn3.bias\n",
      "0.5.3.conv1.weight\n",
      "0.5.3.bn1.weight\n",
      "0.5.3.bn1.bias\n",
      "0.5.3.conv2.weight\n",
      "0.5.3.bn2.weight\n",
      "0.5.3.bn2.bias\n",
      "0.5.3.conv3.weight\n",
      "0.5.3.bn3.weight\n",
      "0.5.3.bn3.bias\n",
      "0.6.0.conv1.weight\n",
      "0.6.0.bn1.weight\n",
      "0.6.0.bn1.bias\n",
      "0.6.0.conv2.weight\n",
      "0.6.0.bn2.weight\n",
      "0.6.0.bn2.bias\n",
      "0.6.0.conv3.weight\n",
      "0.6.0.bn3.weight\n",
      "0.6.0.bn3.bias\n",
      "0.6.0.downsample.0.weight\n",
      "0.6.0.downsample.1.weight\n",
      "0.6.0.downsample.1.bias\n",
      "0.6.1.conv1.weight\n",
      "0.6.1.bn1.weight\n",
      "0.6.1.bn1.bias\n",
      "0.6.1.conv2.weight\n",
      "0.6.1.bn2.weight\n",
      "0.6.1.bn2.bias\n",
      "0.6.1.conv3.weight\n",
      "0.6.1.bn3.weight\n",
      "0.6.1.bn3.bias\n",
      "0.6.2.conv1.weight\n",
      "0.6.2.bn1.weight\n",
      "0.6.2.bn1.bias\n",
      "0.6.2.conv2.weight\n",
      "0.6.2.bn2.weight\n",
      "0.6.2.bn2.bias\n",
      "0.6.2.conv3.weight\n",
      "0.6.2.bn3.weight\n",
      "0.6.2.bn3.bias\n",
      "0.6.3.conv1.weight\n",
      "0.6.3.bn1.weight\n",
      "0.6.3.bn1.bias\n",
      "0.6.3.conv2.weight\n",
      "0.6.3.bn2.weight\n",
      "0.6.3.bn2.bias\n",
      "0.6.3.conv3.weight\n",
      "0.6.3.bn3.weight\n",
      "0.6.3.bn3.bias\n",
      "0.6.4.conv1.weight\n",
      "0.6.4.bn1.weight\n",
      "0.6.4.bn1.bias\n",
      "0.6.4.conv2.weight\n",
      "0.6.4.bn2.weight\n",
      "0.6.4.bn2.bias\n",
      "0.6.4.conv3.weight\n",
      "0.6.4.bn3.weight\n",
      "0.6.4.bn3.bias\n",
      "0.6.5.conv1.weight\n",
      "0.6.5.bn1.weight\n",
      "0.6.5.bn1.bias\n",
      "0.6.5.conv2.weight\n",
      "0.6.5.bn2.weight\n",
      "0.6.5.bn2.bias\n",
      "0.6.5.conv3.weight\n",
      "0.6.5.bn3.weight\n",
      "0.6.5.bn3.bias\n",
      "0.7.0.conv1.weight\n",
      "0.7.0.bn1.weight\n",
      "0.7.0.bn1.bias\n",
      "0.7.0.conv2.weight\n",
      "0.7.0.bn2.weight\n",
      "0.7.0.bn2.bias\n",
      "0.7.0.conv3.weight\n",
      "0.7.0.bn3.weight\n",
      "0.7.0.bn3.bias\n",
      "0.7.0.downsample.0.weight\n",
      "0.7.0.downsample.1.weight\n",
      "0.7.0.downsample.1.bias\n",
      "0.7.1.conv1.weight\n",
      "0.7.1.bn1.weight\n",
      "0.7.1.bn1.bias\n",
      "0.7.1.conv2.weight\n",
      "0.7.1.bn2.weight\n",
      "0.7.1.bn2.bias\n",
      "0.7.1.conv3.weight\n",
      "0.7.1.bn3.weight\n",
      "0.7.1.bn3.bias\n",
      "0.7.2.conv1.weight\n",
      "0.7.2.bn1.weight\n",
      "0.7.2.bn1.bias\n",
      "0.7.2.conv2.weight\n",
      "0.7.2.bn2.weight\n",
      "0.7.2.bn2.bias\n",
      "0.7.2.conv3.weight\n",
      "0.7.2.bn3.weight\n",
      "0.7.2.bn3.bias\n",
      "1.2.weight\n",
      "1.2.bias\n",
      "1.4.weight\n",
      "1.4.bias\n",
      "1.6.weight\n",
      "1.6.bias\n",
      "1.8.weight\n",
      "1.8.bias\n"
     ]
    }
   ],
   "source": [
    "for name, child in learn.model.named_children():\n",
    "       \n",
    "        for name2, params in child.named_parameters():\n",
    "            print(name+\".\"+name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Porting FastAI model to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0685,  0.5951]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones((1,3,224,224))\n",
    "learn.model.eval()\n",
    "\n",
    "learn.model(t.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w = data.valid_ds.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w.process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "view(): argument 'size' must be tuple of ints, but found element of type torch.Size at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3c4ed8a31c7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: view(): argument 'size' must be tuple of ints, but found element of type torch.Size at pos 2"
     ]
    }
   ],
   "source": [
    "data = w.data\n",
    "data = data.view(-1, data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandTransform(tfm=TfmCrop (crop_pad), kwargs={}, p=1.0, resolved={'padding_mode': 'reflection', 'row_pct': 0.5, 'col_pct': 0.5}, do_run=True, is_random=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.valid_ds.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r = data.valid_dl.x[0].data == data.valid_ds.x[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[functools.partial(<function _normalize_batch at 0x7fa6bba40950>, mean=tensor([0.7601, 0.7601, 0.7601]), std=tensor([0.3307, 0.3307, 0.3307]), do_x=True, do_y=False)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.valid_dl.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0057, 0.9943]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(data.valid_dl.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "img should be PIL Image. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bd1f8df64ab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img should be PIL Image. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Got inappropriate size arg: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: img should be PIL Image. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "sample = data.valid_dl.x[0].data\n",
    "\n",
    "sample = torchvision.transforms.Resize((256,256))(sample)\n",
    "\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 832.00 MiB (GPU 0; 10.91 GiB total capacity; 9.80 GiB already allocated; 369.69 MiB free; 3.69 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d932139975a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m     )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 832.00 MiB (GPU 0; 10.91 GiB total capacity; 9.80 GiB already allocated; 369.69 MiB free; 3.69 MiB cached)"
     ]
    }
   ],
   "source": [
    "learn.model(data.valid_dl.x[0].data.unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.valid_dl.x[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <string>(1)<module>()\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()->ImageItemList.../ProcessedData\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(92)__getitem__()\n",
      "-> def __getitem__(self,idxs:int)->Any:\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(93)__getitem__()\n",
      "-> idxs = try_int(idxs)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(94)__getitem__()\n",
      "-> if isinstance(idxs, numbers.Integral): return self.get(idxs)\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(94)__getitem__()->Image (3, 4096, 3328)\n",
      "-> if isinstance(idxs, numbers.Integral): return self.get(idxs)\n",
      "(Pdb) n\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(259)predict()\n",
      "-> def predict(self, item:ItemBase, **kwargs):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(261)predict()\n",
      "-> self.callbacks.append(RecordOnCPU())\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(262)predict()\n",
      "-> batch = self.data.one_item(item)\n",
      "(Pdb) quit\n"
     ]
    }
   ],
   "source": [
    "pdb.run('learn.predict(data.valid_dl.x[0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Image in module fastai.vision.image object:\n",
      "\n",
      "class Image(fastai.core.ItemBase)\n",
      " |  Support applying transforms to image data in `px`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Image\n",
      " |      fastai.core.ItemBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, px:torch.Tensor)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  affine(self, func:Callable[[Dict[str, Any]], torch.Tensor], *args, **kwargs) -> 'Image'\n",
      " |      Equivalent to `image.affine_mat = image.affine_mat @ func()`.\n",
      " |  \n",
      " |  apply_tfms(self, tfms:Union[Callable, Collection[Callable]], do_resolve:bool=True, xtra:Union[Dict[Callable, dict], NoneType]=None, size:Union[int, Tuple[int, int, int], NoneType]=None, resize_method:fastai.vision.image.ResizeMethod=<ResizeMethod.CROP: 1>, mult:int=32, padding_mode:str='reflection', mode:str='bilinear') -> torch.Tensor\n",
      " |      Apply all `tfms` to the `Image`, if `do_resolve` picks value for random args.\n",
      " |  \n",
      " |  brightness lambda x, *args, **kwargs\n",
      " |  \n",
      " |  clone(self)\n",
      " |      Mimic the behavior of torch.clone for `Image` objects.\n",
      " |  \n",
      " |  contrast lambda x, *args, **kwargs\n",
      " |  \n",
      " |  coord(self, func:Callable[[fastai.vision.image.FlowField, Collection[Any], Dict[str, Any]], torch.Tensor], *args, **kwargs) -> 'Image'\n",
      " |      Equivalent to `image.flow = func(image.flow, image.size)`.\n",
      " |  \n",
      " |  crop lambda x, *args, **kwargs\n",
      " |  \n",
      " |  crop_pad lambda x, *args, **kwargs\n",
      " |  \n",
      " |  dihedral lambda x, *args, **kwargs\n",
      " |  \n",
      " |  dihedral_affine lambda x, *args, **kwargs\n",
      " |  \n",
      " |  flip_affine lambda x, *args, **kwargs\n",
      " |  \n",
      " |  flip_lr lambda x, *args, **kwargs\n",
      " |  \n",
      " |  jitter lambda x, *args, **kwargs\n",
      " |  \n",
      " |  lighting(self, func:Callable[[torch.Tensor, Collection[Any], Dict[str, Any]], torch.Tensor], *args:Any, **kwargs:Any)\n",
      " |      Equivalent to `image = sigmoid(func(logit(image)))`.\n",
      " |  \n",
      " |  pad lambda x, *args, **kwargs\n",
      " |  \n",
      " |  perspective_warp lambda x, *args, **kwargs\n",
      " |  \n",
      " |  pixel(self, func:Callable[[torch.Tensor, Collection[Any], Dict[str, Any]], torch.Tensor], *args, **kwargs) -> 'Image'\n",
      " |      Equivalent to `image.px = func(image.px)`.\n",
      " |  \n",
      " |  refresh(self) -> None\n",
      " |      Apply any logit, flow, or affine transfers that have been sent to the `Image`.\n",
      " |  \n",
      " |  resize(self, size:Union[int, Tuple[int, int, int]]) -> 'Image'\n",
      " |      Resize the image to `size`, size can be a single int.\n",
      " |  \n",
      " |  rotate lambda x, *args, **kwargs\n",
      " |  \n",
      " |  save(self, fn:Union[pathlib.Path, str])\n",
      " |      Save the image to `fn`.\n",
      " |  \n",
      " |  set_sample(self, **kwargs) -> 'ImageBase'\n",
      " |      Set parameters that control how we `grid_sample` the image after transforms are applied.\n",
      " |  \n",
      " |  show(self, ax:matplotlib.axes._axes.Axes=None, figsize:tuple=(3, 3), title:Union[str, NoneType]=None, hide_axis:bool=True, cmap:str=None, y:Any=None, **kwargs)\n",
      " |      Show image on `ax` with `title`, using `cmap` if single-channel, overlaid with optional `y`\n",
      " |  \n",
      " |  skew lambda x, *args, **kwargs\n",
      " |  \n",
      " |  squish lambda x, *args, **kwargs\n",
      " |  \n",
      " |  symmetric_warp lambda x, *args, **kwargs\n",
      " |  \n",
      " |  tilt lambda x, *args, **kwargs\n",
      " |  \n",
      " |  zoom lambda x, *args, **kwargs\n",
      " |  \n",
      " |  zoom_squish lambda x, *args, **kwargs\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  affine_mat\n",
      " |      Get the affine matrix that will be applied by `refresh`.\n",
      " |  \n",
      " |  data\n",
      " |      Return this images pixels as a tensor.\n",
      " |  \n",
      " |  device\n",
      " |  \n",
      " |  flow\n",
      " |      Access the flow-field grid after applying queued affine transforms.\n",
      " |  \n",
      " |  logit_px\n",
      " |      Get logit(image.px).\n",
      " |  \n",
      " |  px\n",
      " |      Get the tensor pixel buffer.\n",
      " |  \n",
      " |  shape\n",
      " |  \n",
      " |  size\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from fastai.core.ItemBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e = data.train_ds.x[0]\n",
    "\n",
    "help(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         ...,\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.vision.data.ImageItemList"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.train_dl.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.vision.data.ImageItemList"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.train_ds.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data_block.LabelList"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.basic_data.DeviceDataLoader"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.vision.image.Image"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.train_ds.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.vision.data.ImageDataBunch"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q=learn.data.one_item(data.valid_dl.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8241,  2.3344]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.eval()\n",
    "nn.Softmaxlearn.model(q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0057, 0.9943]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(data.valid_dl.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'fastai.vision.image.Image'>, <class 'fastai.core.ItemBase'>, <class 'object'>)\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getmro(fastai.vision.image.Image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'fastai.core.ItemBase'>, <class 'object'>)\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getmro(fastai.core.ItemBase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = Image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating PredList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7552/7552 [29:14<00:00,  4.77it/s]\n"
     ]
    }
   ],
   "source": [
    "predList = []\n",
    "\n",
    "for i in tqdm(range(len(data.valid_ds))):\n",
    "    pred = learn.predict(data.valid_dl.x[i])\n",
    "    predList.append(pred)\n",
    "\n",
    "# help(learn.get_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Creating Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "predScores = []\n",
    "\n",
    "for i in range(len(predList)):\n",
    "    predScores.append([predList[i][2].numpy()[0],predList[i][2].numpy()[1]])\n",
    "\n",
    "predLabels = []\n",
    "\n",
    "for i in range(len(predList)):\n",
    "    predLabels.append(int(predList[i][1].numpy()))\n",
    "\n",
    "imageNames = []\n",
    "\n",
    "for i in range(len(data.valid_ds)):\n",
    "    imageNames.append( data.valid_ds.items[i].split(\"/\")[-1].split(\".\")[0]  )\n",
    "\n",
    "\n",
    "predDf = pd.DataFrame(predScores)\n",
    "predDf.columns = ['score0','score1']\n",
    "\n",
    "predDf['predLabel'] = predLabels\n",
    "\n",
    "predDf['imageName'] = imageNames\n",
    "\n",
    "predDf['truthLabel'] = predDf.imageName.apply(lambda x : getRaceLabel(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score0</th>\n",
       "      <th>score1</th>\n",
       "      <th>predLabel</th>\n",
       "      <th>imageName</th>\n",
       "      <th>truthLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>1</td>\n",
       "      <td>75048084_R_CC_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803633</td>\n",
       "      <td>0.196367</td>\n",
       "      <td>0</td>\n",
       "      <td>76876308_R_MLO_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.208912</td>\n",
       "      <td>0.791088</td>\n",
       "      <td>1</td>\n",
       "      <td>76750724_FOR-PROCESSING_L_CC_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997835</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0</td>\n",
       "      <td>76809071_R_CC_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.929431</td>\n",
       "      <td>0.070569</td>\n",
       "      <td>0</td>\n",
       "      <td>75352509_L_MLO_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     score0    score1  predLabel                       imageName  truthLabel\n",
       "0  0.005717  0.994283          1                 75048084_R_CC_1           1\n",
       "1  0.803633  0.196367          0                76876308_R_MLO_1           1\n",
       "2  0.208912  0.791088          1  76750724_FOR-PROCESSING_L_CC_1           1\n",
       "3  0.997835  0.002165          0                 76809071_R_CC_1           0\n",
       "4  0.929431  0.070569          0                75352509_L_MLO_1           0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8334216101694916"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predDf.predLabel, predDf.truthLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predDf.to_csv('model10_1_Predictions.csv',index = False, index_label = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score0</th>\n",
       "      <th>score1</th>\n",
       "      <th>predLabel</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>truthLabel</th>\n",
       "      <th>DummyID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>1</td>\n",
       "      <td>75048084_R_CC_1</td>\n",
       "      <td>1</td>\n",
       "      <td>75048084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803633</td>\n",
       "      <td>0.196367</td>\n",
       "      <td>0</td>\n",
       "      <td>76876308_R_MLO_1</td>\n",
       "      <td>1</td>\n",
       "      <td>76876308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.208912</td>\n",
       "      <td>0.791088</td>\n",
       "      <td>1</td>\n",
       "      <td>76750724_FOR-PROCESSING_L_CC_1</td>\n",
       "      <td>1</td>\n",
       "      <td>76750724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997835</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0</td>\n",
       "      <td>76809071_R_CC_1</td>\n",
       "      <td>0</td>\n",
       "      <td>76809071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.929431</td>\n",
       "      <td>0.070569</td>\n",
       "      <td>0</td>\n",
       "      <td>75352509_L_MLO_1</td>\n",
       "      <td>0</td>\n",
       "      <td>75352509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     score0    score1  predLabel                       ImageName  truthLabel  \\\n",
       "0  0.005717  0.994283          1                 75048084_R_CC_1           1   \n",
       "1  0.803633  0.196367          0                76876308_R_MLO_1           1   \n",
       "2  0.208912  0.791088          1  76750724_FOR-PROCESSING_L_CC_1           1   \n",
       "3  0.997835  0.002165          0                 76809071_R_CC_1           0   \n",
       "4  0.929431  0.070569          0                75352509_L_MLO_1           0   \n",
       "\n",
       "    DummyID  \n",
       "0  75048084  \n",
       "1  76876308  \n",
       "2  76750724  \n",
       "3  76809071  \n",
       "4  75352509  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score0</th>\n",
       "      <th>score1</th>\n",
       "      <th>predLabel</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>truthLabel</th>\n",
       "      <th>DummyID</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [score0, score1, predLabel, ImageName, truthLabel, DummyID, BMI]\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predDf[predDf.DummyID==75923459]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(predDf.DummyID.values).intersection(set(trainPredDf.DummyID.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Predictions at BMI level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDf = pd.read_csv('model10_1_Predictions.csv')\n",
    "\n",
    "truth = truth.sort_values(['DummyID','BMI'])\n",
    "\n",
    "truth = truth.drop_duplicates(subset=['DummyID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'imageName' in predDf.columns:\n",
    "    predDf.rename(columns={'imageName':'ImageName'},inplace=True)\n",
    "    \n",
    "predDf['DummyID'] = predDf.ImageName.apply(lambda x : int(x.split(\"_\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7552.000000\n",
       "mean       27.504449\n",
       "std         6.002899\n",
       "min         2.700000\n",
       "25%        23.400000\n",
       "50%        26.600000\n",
       "75%        29.800000\n",
       "max        67.500000\n",
       "Name: BMI, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "predDf = pd.merge(predDf, truth[['DummyID','BMI']], on='DummyID',how='left')\n",
    "\n",
    "#Removing samples which dont have BMI\n",
    "predDf = predDf[~predDf.BMI.isnull()]\n",
    "\n",
    "predDf.BMI.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 80)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.title(\"White\")\n",
    "plt.hist(predDf[predDf.truthLabel==1]['BMI'])\n",
    "plt.xlim(0,80)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"African American\")\n",
    "plt.hist(predDf[predDf.truthLabel==0]['BMI'])\n",
    "plt.xlim(0,80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI_min</th>\n",
       "      <th>BMI_max</th>\n",
       "      <th>Total Acc</th>\n",
       "      <th>White Acc</th>\n",
       "      <th>Black Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BMI_min  BMI_max  Total Acc  White Acc  Black Acc\n",
       "0       15       20       0.80       0.82       0.78\n",
       "1       20       25       0.85       0.88       0.82\n",
       "2       25       30       0.82       0.85       0.80\n",
       "3       30       35       0.83       0.83       0.82\n",
       "4       35       40       0.83       0.81       0.85\n",
       "5       40       45       0.79       0.80       0.78\n",
       "6       45       50       0.86       0.81       0.91\n",
       "7       50       55       0.92       0.92       0.92"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputData = []\n",
    "for i in range(8):\n",
    "    bmi_min,bmi_max = 15 + 5*i, 15 + 5*(i+1)\n",
    "    \n",
    "    subDf = predDf[predDf.BMI.between(bmi_min,bmi_max)]\n",
    "    \n",
    "    whiteDf = subDf[subDf.truthLabel==1]\n",
    "    aaDf = subDf[subDf.truthLabel==0]\n",
    "    \n",
    "    selectSize = min(len(whiteDf), len(aaDf))\n",
    "    \n",
    "    whiteDf = whiteDf[:selectSize]\n",
    "    aaDf = aaDf[:selectSize]\n",
    "    \n",
    "    tempDf = pd.concat([whiteDf, aaDf])\n",
    "    \n",
    "    whiteAcc = np.round(accuracy_score(whiteDf.truthLabel, whiteDf.predLabel),2)\n",
    "    aaAcc = np.round(accuracy_score(aaDf.truthLabel, aaDf.predLabel),2)\n",
    "    \n",
    "    acc = np.round(accuracy_score(tempDf.truthLabel,tempDf.predLabel),2)\n",
    "    \n",
    "    outputData.append([bmi_min, bmi_max, selectSize, acc, whiteAcc,aaAcc])\n",
    "\n",
    "\n",
    "    \n",
    "tempDf = pd.DataFrame(outputData)\n",
    "tempDf.columns = ['BMI_min','BMI_max','numImages','Total Acc','White Acc','Black Acc']\n",
    "\n",
    "tempDf[['BMI_min','BMI_max','Total Acc','White Acc','Black Acc']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI_min</th>\n",
       "      <th>BMI_max</th>\n",
       "      <th>numImages</th>\n",
       "      <th>Total Acc</th>\n",
       "      <th>White Acc</th>\n",
       "      <th>Black Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>344</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>2504</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>3080</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>988</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>504</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>176</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BMI_min  BMI_max  numImages  Total Acc  White Acc  Black Acc\n",
       "0       15       20        344       0.80       0.81       0.78\n",
       "1       20       25       2504       0.87       0.89       0.82\n",
       "2       25       30       3080       0.81       0.85       0.79\n",
       "3       30       35        988       0.82       0.83       0.82\n",
       "4       35       40        504       0.83       0.81       0.85\n",
       "5       40       45        176       0.77       0.76       0.78\n",
       "6       45       50         88       0.86       0.81       0.89\n",
       "7       50       55         28       0.89       0.92       0.88"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputData = []\n",
    "for i in range(8):\n",
    "    bmi_min,bmi_max = 15 + 5*i, 15 + 5*(i+1)\n",
    "    \n",
    "    subDf = predDf[predDf.BMI.between(bmi_min,bmi_max)]\n",
    "    \n",
    "    whiteDf = subDf[subDf.truthLabel==1]\n",
    "    aaDf = subDf[subDf.truthLabel==0]\n",
    "        \n",
    "    tempDf = pd.concat([whiteDf, aaDf])\n",
    "    \n",
    "    whiteAcc = np.round(accuracy_score(whiteDf.truthLabel, whiteDf.predLabel),2)\n",
    "    aaAcc = np.round(accuracy_score(aaDf.truthLabel, aaDf.predLabel),2)\n",
    "    \n",
    "    acc = np.round(accuracy_score(tempDf.truthLabel,tempDf.predLabel),2)\n",
    "    \n",
    "    outputData.append([bmi_min, bmi_max, len(subDf), acc, whiteAcc,aaAcc])\n",
    "\n",
    "    \n",
    "tempDf = pd.DataFrame(outputData)\n",
    "tempDf.columns = ['BMI_min','BMI_max','numImages','Total Acc','White Acc','Black Acc']\n",
    "\n",
    "totalDiff = 0\n",
    "\n",
    "for i in range(len(tempDf)):\n",
    "    \n",
    "    diff = np.abs(tempDf.iloc[i]['White Acc'] - tempDf.iloc[i]['Black Acc'])\n",
    "    \n",
    "    totalDiff += diff\n",
    "    \n",
    "\n",
    "biasScore = totalDiff/len(tempDf)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Checking Predictions at Breast Volume level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>DummyID</th>\n",
       "      <th>BreastSide</th>\n",
       "      <th>MammoView</th>\n",
       "      <th>BreastVolumeCm3</th>\n",
       "      <th>VolumetricBreastDensity</th>\n",
       "      <th>DenseAreaPercent</th>\n",
       "      <th>ComputedBreastThickness</th>\n",
       "      <th>MaximumPercentDensityIn1Cm2Area</th>\n",
       "      <th>MaximumDenseVolumeIn1Cm2AreaInCm3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2036311_L_CC_1</td>\n",
       "      <td>2036311</td>\n",
       "      <td>Left</td>\n",
       "      <td>CC</td>\n",
       "      <td>551.8933</td>\n",
       "      <td>5.2457</td>\n",
       "      <td>67.1112</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16.3976</td>\n",
       "      <td>1.047380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2036311_L_MLO_1</td>\n",
       "      <td>2036311</td>\n",
       "      <td>Left</td>\n",
       "      <td>MLO</td>\n",
       "      <td>638.1189</td>\n",
       "      <td>10.5883</td>\n",
       "      <td>92.3699</td>\n",
       "      <td>63.0</td>\n",
       "      <td>25.2581</td>\n",
       "      <td>1.639360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2036311_R_CC_1</td>\n",
       "      <td>2036311</td>\n",
       "      <td>Right</td>\n",
       "      <td>CC</td>\n",
       "      <td>468.4220</td>\n",
       "      <td>4.6236</td>\n",
       "      <td>39.2641</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14.5975</td>\n",
       "      <td>0.842166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2036311_R_MLO_1</td>\n",
       "      <td>2036311</td>\n",
       "      <td>Right</td>\n",
       "      <td>MLO</td>\n",
       "      <td>712.3350</td>\n",
       "      <td>7.1716</td>\n",
       "      <td>85.2747</td>\n",
       "      <td>70.0</td>\n",
       "      <td>20.8634</td>\n",
       "      <td>1.504580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2043167_L_CC_1</td>\n",
       "      <td>2043167</td>\n",
       "      <td>Left</td>\n",
       "      <td>CC</td>\n",
       "      <td>1441.5069</td>\n",
       "      <td>5.9439</td>\n",
       "      <td>33.3823</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13.7715</td>\n",
       "      <td>0.993140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageName  DummyID BreastSide MammoView  BreastVolumeCm3  \\\n",
       "0   2036311_L_CC_1  2036311       Left        CC         551.8933   \n",
       "1  2036311_L_MLO_1  2036311       Left       MLO         638.1189   \n",
       "2   2036311_R_CC_1  2036311      Right        CC         468.4220   \n",
       "3  2036311_R_MLO_1  2036311      Right       MLO         712.3350   \n",
       "4   2043167_L_CC_1  2043167       Left        CC        1441.5069   \n",
       "\n",
       "   VolumetricBreastDensity  DenseAreaPercent  ComputedBreastThickness  \\\n",
       "0                   5.2457           67.1112                     62.0   \n",
       "1                  10.5883           92.3699                     63.0   \n",
       "2                   4.6236           39.2641                     56.0   \n",
       "3                   7.1716           85.2747                     70.0   \n",
       "4                   5.9439           33.3823                     70.0   \n",
       "\n",
       "   MaximumPercentDensityIn1Cm2Area  MaximumDenseVolumeIn1Cm2AreaInCm3  \n",
       "0                          16.3976                           1.047380  \n",
       "1                          25.2581                           1.639360  \n",
       "2                          14.5975                           0.842166  \n",
       "3                          20.8634                           1.504580  \n",
       "4                          13.7715                           0.993140  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volpara = pd.read_csv(\"VolparaResults.csv\")\n",
    "volpara.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predDf = pd.merge(predDf, volpara[['ImageName','BreastVolumeCm3']], on='ImageName', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 262 rows with missing volume information\n"
     ]
    }
   ],
   "source": [
    "preCount = len(predDf)\n",
    "predDf = predDf[~pd.isna(predDf.BreastVolumeCm3)]\n",
    "print(\"Dropped {} rows with missing volume information\".format(preCount - len(predDf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 567., 1211.,  920.,  518.,  243.,  123.,   79.,   32.,    8.,    7.]),\n",
       " array([  60.5711 ,  465.90718,  871.24326, 1276.57934, 1681.91542, 2087.2515 , 2492.58758, 2897.92366, 3303.25974,\n",
       "        3708.59582, 4113.9319 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.title(\"White\")\n",
    "plt.hist(predDf[predDf.truthLabel==1]['BreastVolumeCm3'])\n",
    "# plt.xlim(0,80)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"African American\")\n",
    "plt.hist(predDf[predDf.truthLabel==0]['BreastVolumeCm3'])\n",
    "# plt.xlim(0,80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cuts = np.quantile(predDf.BreastVolumeCm3, [i/10 for i in range(11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI_min</th>\n",
       "      <th>BMI_max</th>\n",
       "      <th>numImages</th>\n",
       "      <th>Total Acc</th>\n",
       "      <th>White Acc</th>\n",
       "      <th>Black Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.57110</td>\n",
       "      <td>350.53756</td>\n",
       "      <td>318</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350.53756</td>\n",
       "      <td>481.92662</td>\n",
       "      <td>288</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481.92662</td>\n",
       "      <td>600.76925</td>\n",
       "      <td>343</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600.76925</td>\n",
       "      <td>719.84100</td>\n",
       "      <td>359</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>719.84100</td>\n",
       "      <td>843.49760</td>\n",
       "      <td>352</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843.49760</td>\n",
       "      <td>984.14228</td>\n",
       "      <td>346</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>984.14228</td>\n",
       "      <td>1138.70128</td>\n",
       "      <td>337</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1138.70128</td>\n",
       "      <td>1384.62894</td>\n",
       "      <td>324</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1384.62894</td>\n",
       "      <td>1780.06990</td>\n",
       "      <td>299</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1780.06990</td>\n",
       "      <td>4113.93190</td>\n",
       "      <td>316</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BMI_min     BMI_max  numImages  Total Acc  White Acc  Black Acc\n",
       "0    60.57110   350.53756        318       0.81       0.84       0.78\n",
       "1   350.53756   481.92662        288       0.84       0.90       0.79\n",
       "2   481.92662   600.76925        343       0.86       0.89       0.82\n",
       "3   600.76925   719.84100        359       0.83       0.89       0.76\n",
       "4   719.84100   843.49760        352       0.83       0.88       0.78\n",
       "5   843.49760   984.14228        346       0.85       0.88       0.81\n",
       "6   984.14228  1138.70128        337       0.83       0.85       0.81\n",
       "7  1138.70128  1384.62894        324       0.81       0.80       0.83\n",
       "8  1384.62894  1780.06990        299       0.85       0.82       0.88\n",
       "9  1780.06990  4113.93190        316       0.83       0.78       0.88"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputData = []\n",
    "for i in range(10):\n",
    "    bmi_min,bmi_max = cuts[i], cuts[i+1]\n",
    "    \n",
    "    subDf = predDf[predDf.BreastVolumeCm3.between(bmi_min,bmi_max)]\n",
    "    \n",
    "    whiteDf = subDf[subDf.truthLabel==1]\n",
    "    aaDf = subDf[subDf.truthLabel==0]\n",
    "    \n",
    "    selectSize = min(len(whiteDf), len(aaDf))\n",
    "    \n",
    "    whiteDf = whiteDf[:selectSize]\n",
    "    aaDf = aaDf[:selectSize]\n",
    "    \n",
    "    tempDf = pd.concat([whiteDf, aaDf])\n",
    "    \n",
    "    whiteAcc = np.round(accuracy_score(whiteDf.truthLabel, whiteDf.predLabel),2)\n",
    "    aaAcc = np.round(accuracy_score(aaDf.truthLabel, aaDf.predLabel),2)\n",
    "    \n",
    "    acc = np.round(accuracy_score(tempDf.truthLabel,tempDf.predLabel),2)\n",
    "    \n",
    "    outputData.append([bmi_min, bmi_max, selectSize, acc, whiteAcc,aaAcc])\n",
    "\n",
    "\n",
    "    \n",
    "tempDf = pd.DataFrame(outputData)\n",
    "tempDf.columns = ['BMI_min','BMI_max','numImages','Total Acc','White Acc','Black Acc']\n",
    "\n",
    "tempDf\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tempDf.to_csv('VolumeBucket_Results.csv',index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Predictions at Density Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (65,66,67,68,69) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "truthFile = '/home/santhosr/Documents/Birad/FastAI/RaceClassification/Final.csv'\n",
    "truth1 = pd.read_csv(truthFile)\n",
    "\n",
    "keepList = ['ImageName','VolumetricBreastDensity','DenseAreaPercent']\n",
    "temp1 = truth1[keepList] \n",
    "\n",
    "\n",
    "\n",
    "# temp2 = pd.read_csv('/home/santhosr/Documents/Birad/Breast_density_data.csv')\n",
    "\n",
    "# temp2['DenseAreaPercent'] = (temp2['DenseArea(sqcm)']/temp2['BreastArea(sqcm)'])*100\n",
    "\n",
    "# temp2 = temp2[['File Analyzed' , 'DenseAreaPercent'] ]\n",
    "\n",
    "# temp2.columns = ['ImageName','DenseAreaPercent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDf = pd.read_csv('model9_1_Predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDf = predDf.merge(temp1, on='ImageName',how='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDf = predDf[~pd.isna(predDf.DenseAreaPercent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5636"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([550., 631., 497., 406., 376., 342., 310., 338., 275., 147.]),\n",
       " array([2.568240e-02, 1.002311e+01, 2.002055e+01, 3.001798e+01, 4.001541e+01, 5.001284e+01, 6.001027e+01, 7.000770e+01,\n",
       "        8.000514e+01, 9.000257e+01, 1.000000e+02]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.title(\"White\")\n",
    "plt.hist(predDf[predDf.truthLabel==1]['DenseAreaPercent'])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"African American\")\n",
    "plt.hist(predDf[predDf.truthLabel==0]['DenseAreaPercent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "temp1['race'] = temp1.ImageName.apply(getRaceLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>VolumetricBreastDensity</th>\n",
       "      <th>DenseAreaPercent</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2036311_L_CC_1</td>\n",
       "      <td>5.2457</td>\n",
       "      <td>67.1112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2036311_L_MLO_1</td>\n",
       "      <td>10.5883</td>\n",
       "      <td>92.3699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2036311_L_MLO_2</td>\n",
       "      <td>5.1084</td>\n",
       "      <td>55.4036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2036311_R_CC_1</td>\n",
       "      <td>4.6236</td>\n",
       "      <td>39.2641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2036311_R_MLO_1</td>\n",
       "      <td>7.1716</td>\n",
       "      <td>85.2747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageName  VolumetricBreastDensity  DenseAreaPercent  race\n",
       "0   2036311_L_CC_1                   5.2457           67.1112     1\n",
       "1  2036311_L_MLO_1                  10.5883           92.3699     1\n",
       "2  2036311_L_MLO_2                   5.1084           55.4036     1\n",
       "3   2036311_R_CC_1                   4.6236           39.2641     1\n",
       "4  2036311_R_MLO_1                   7.1716           85.2747     1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Density_min</th>\n",
       "      <th>Density_max</th>\n",
       "      <th>numImages</th>\n",
       "      <th>Total Acc</th>\n",
       "      <th>White Acc</th>\n",
       "      <th>Black Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>178</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>138</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>146</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>171</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>164</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>189</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>229</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Density_min  Density_max  numImages  Total Acc  White Acc  Black Acc\n",
       "0           10           20        178       0.83       0.80       0.85\n",
       "1           20           30        149       0.86       0.83       0.89\n",
       "2           30           40        138       0.84       0.80       0.88\n",
       "3           40           50        146       0.87       0.87       0.86\n",
       "4           50           60        171       0.85       0.86       0.84\n",
       "5           60           70        164       0.87       0.91       0.83\n",
       "6           70           80        189       0.84       0.90       0.78\n",
       "7           80           90        229       0.81       0.95       0.68"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputData = []\n",
    "for i in range(8):\n",
    "    bmi_min,bmi_max = 10 + 10*i, 10 + 10*(i+1)\n",
    "    \n",
    "    subDf = predDf[predDf.DenseAreaPercent.between(bmi_min,bmi_max)]\n",
    "    \n",
    "    whiteDf = subDf[subDf.truthLabel==1]\n",
    "    aaDf = subDf[subDf.truthLabel==0]\n",
    "    \n",
    "    selectSize = min(len(whiteDf), len(aaDf))\n",
    "    \n",
    "    whiteDf = whiteDf[:selectSize]\n",
    "    aaDf = aaDf[:selectSize]\n",
    "    \n",
    "    tempDf = pd.concat([whiteDf, aaDf])\n",
    "    \n",
    "    whiteAcc = np.round(accuracy_score(whiteDf.truthLabel, whiteDf.predLabel),2)\n",
    "    aaAcc = np.round(accuracy_score(aaDf.truthLabel, aaDf.predLabel),2)\n",
    "    \n",
    "    acc = np.round(accuracy_score(tempDf.truthLabel,tempDf.predLabel),2)\n",
    "    \n",
    "    outputData.append([bmi_min, bmi_max, selectSize, acc, whiteAcc,aaAcc])\n",
    "\n",
    "    \n",
    "tempDf = pd.DataFrame(outputData)\n",
    "tempDf.columns = ['Density_min','Density_max','numImages','Total Acc','White Acc','Black Acc']\n",
    "\n",
    "tempDf\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score0</th>\n",
       "      <th>score1</th>\n",
       "      <th>predLabel</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>truthLabel</th>\n",
       "      <th>DummyID</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.994283</td>\n",
       "      <td>1</td>\n",
       "      <td>75048084_R_CC_1</td>\n",
       "      <td>1</td>\n",
       "      <td>75048084</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803633</td>\n",
       "      <td>0.196367</td>\n",
       "      <td>0</td>\n",
       "      <td>76876308_R_MLO_1</td>\n",
       "      <td>1</td>\n",
       "      <td>76876308</td>\n",
       "      <td>21.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.208912</td>\n",
       "      <td>0.791088</td>\n",
       "      <td>1</td>\n",
       "      <td>76750724_FOR-PROCESSING_L_CC_1</td>\n",
       "      <td>1</td>\n",
       "      <td>76750724</td>\n",
       "      <td>30.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997835</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0</td>\n",
       "      <td>76809071_R_CC_1</td>\n",
       "      <td>0</td>\n",
       "      <td>76809071</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.929431</td>\n",
       "      <td>0.070569</td>\n",
       "      <td>0</td>\n",
       "      <td>75352509_L_MLO_1</td>\n",
       "      <td>0</td>\n",
       "      <td>75352509</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     score0    score1  predLabel                       ImageName  truthLabel  \\\n",
       "0  0.005717  0.994283          1                 75048084_R_CC_1           1   \n",
       "1  0.803633  0.196367          0                76876308_R_MLO_1           1   \n",
       "2  0.208912  0.791088          1  76750724_FOR-PROCESSING_L_CC_1           1   \n",
       "3  0.997835  0.002165          0                 76809071_R_CC_1           0   \n",
       "4  0.929431  0.070569          0                75352509_L_MLO_1           0   \n",
       "\n",
       "    DummyID   BMI  \n",
       "0  75048084  24.8  \n",
       "1  76876308  21.3  \n",
       "2  76750724  30.9  \n",
       "3  76809071  33.3  \n",
       "4  75352509  18.3  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4186820</td>\n",
       "      <td>FullRes/3/4186820_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76789629</td>\n",
       "      <td>FullRes/2/76789629_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75073273</td>\n",
       "      <td>FullRes/3/75073273_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75577074</td>\n",
       "      <td>FullRes/2/75577074_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76671221</td>\n",
       "      <td>FullRes/2/76671221_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DummyID                        filename  train\n",
       "0   4186820   FullRes/3/4186820_R_MLO_1.jpg  False\n",
       "1  76789629  FullRes/2/76789629_R_MLO_1.jpg  False\n",
       "2  75073273  FullRes/3/75073273_R_MLO_1.jpg  False\n",
       "3  75577074   FullRes/2/75577074_L_CC_1.jpg  False\n",
       "4  76671221   FullRes/2/76671221_L_CC_1.jpg  False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combined Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4186820</td>\n",
       "      <td>FullRes/3/4186820_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76789629</td>\n",
       "      <td>FullRes/2/76789629_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75073273</td>\n",
       "      <td>FullRes/3/75073273_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75577074</td>\n",
       "      <td>FullRes/2/75577074_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76671221</td>\n",
       "      <td>FullRes/2/76671221_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DummyID                        filename  train\n",
       "0   4186820   FullRes/3/4186820_R_MLO_1.jpg  False\n",
       "1  76789629  FullRes/2/76789629_R_MLO_1.jpg  False\n",
       "2  75073273  FullRes/3/75073273_R_MLO_1.jpg  False\n",
       "3  75577074   FullRes/2/75577074_L_CC_1.jpg  False\n",
       "4  76671221   FullRes/2/76671221_L_CC_1.jpg  False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Density_Overall</th>\n",
       "      <th>DummyID</th>\n",
       "      <th>Medview_Race</th>\n",
       "      <th>ScreenDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.8</td>\n",
       "      <td>27.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2508626</td>\n",
       "      <td>White</td>\n",
       "      <td>3/23/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.8</td>\n",
       "      <td>25.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2505738</td>\n",
       "      <td>White</td>\n",
       "      <td>6/2/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.4</td>\n",
       "      <td>28.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2547962</td>\n",
       "      <td>White</td>\n",
       "      <td>5/24/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.7</td>\n",
       "      <td>31.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2575490</td>\n",
       "      <td>White</td>\n",
       "      <td>5/6/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.7</td>\n",
       "      <td>27.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2591080</td>\n",
       "      <td>Other</td>\n",
       "      <td>5/5/2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age   BMI  Density_Overall  DummyID Medview_Race ScreenDate\n",
       "0  67.8  27.1              2.0  2508626        White  3/23/2011\n",
       "1  58.8  25.7              2.0  2505738        White   6/2/2011\n",
       "2  56.4  28.1              2.0  2547962        White  5/24/2011\n",
       "3  51.7  31.8              2.0  2575490        White   5/6/2011\n",
       "4  63.7  27.5              2.0  2591080        Other   5/5/2011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['label'] = df.filename.apply(lambda x : getRaceLabel(x))\n",
    "\n",
    "df['DummyID'] = df.filename.apply(lambda x : int(x.split(\"/\")[-1].split(\"_\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extractImageName(x):\n",
    "    \n",
    "    x = x.split(\"/\")[-1]\n",
    "    \n",
    "    if \"MLO\" in x :\n",
    "        return x[-11:-6]\n",
    "    else:\n",
    "        return x[-10:-6]\n",
    "    \n",
    "df['ImageName'] = df.filename.apply(lambda x : x.split(\"/\")[-1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "      <th>label</th>\n",
       "      <th>ImageName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4186820</td>\n",
       "      <td>FullRes/3/4186820_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4186820_R_MLO_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76789629</td>\n",
       "      <td>FullRes/2/76789629_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>76789629_R_MLO_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75073273</td>\n",
       "      <td>FullRes/3/75073273_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>75073273_R_MLO_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75577074</td>\n",
       "      <td>FullRes/2/75577074_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>75577074_L_CC_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76671221</td>\n",
       "      <td>FullRes/2/76671221_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>76671221_L_CC_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DummyID                        filename  train  label         ImageName\n",
       "0   4186820   FullRes/3/4186820_R_MLO_1.jpg  False      0   4186820_R_MLO_1\n",
       "1  76789629  FullRes/2/76789629_R_MLO_1.jpg  False      1  76789629_R_MLO_1\n",
       "2  75073273  FullRes/3/75073273_R_MLO_1.jpg  False      0  75073273_R_MLO_1\n",
       "3  75577074   FullRes/2/75577074_L_CC_1.jpg  False      1   75577074_L_CC_1\n",
       "4  76671221   FullRes/2/76671221_L_CC_1.jpg  False      0   76671221_L_CC_1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, truth[['DummyID','Age','BMI']], on='DummyID', how='left')\n",
    "\n",
    "#Removing instances without BMI\n",
    "df = df.loc[~pd.isna(df.BMI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    21264\n",
       "0    18840\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Volpara results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = pd.read_csv('VolparaResults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>DummyID</th>\n",
       "      <th>BreastSide</th>\n",
       "      <th>MammoView</th>\n",
       "      <th>BreastVolumeCm3</th>\n",
       "      <th>VolumetricBreastDensity</th>\n",
       "      <th>DenseAreaPercent</th>\n",
       "      <th>ComputedBreastThickness</th>\n",
       "      <th>MaximumPercentDensityIn1Cm2Area</th>\n",
       "      <th>MaximumDenseVolumeIn1Cm2AreaInCm3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2036311_L_CC_1</td>\n",
       "      <td>2036311</td>\n",
       "      <td>Left</td>\n",
       "      <td>CC</td>\n",
       "      <td>551.8933</td>\n",
       "      <td>5.2457</td>\n",
       "      <td>67.1112</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16.3976</td>\n",
       "      <td>1.047380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2036311_L_MLO_1</td>\n",
       "      <td>2036311</td>\n",
       "      <td>Left</td>\n",
       "      <td>MLO</td>\n",
       "      <td>638.1189</td>\n",
       "      <td>10.5883</td>\n",
       "      <td>92.3699</td>\n",
       "      <td>63.0</td>\n",
       "      <td>25.2581</td>\n",
       "      <td>1.639360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2036311_R_CC_1</td>\n",
       "      <td>2036311</td>\n",
       "      <td>Right</td>\n",
       "      <td>CC</td>\n",
       "      <td>468.4220</td>\n",
       "      <td>4.6236</td>\n",
       "      <td>39.2641</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14.5975</td>\n",
       "      <td>0.842166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2036311_R_MLO_1</td>\n",
       "      <td>2036311</td>\n",
       "      <td>Right</td>\n",
       "      <td>MLO</td>\n",
       "      <td>712.3350</td>\n",
       "      <td>7.1716</td>\n",
       "      <td>85.2747</td>\n",
       "      <td>70.0</td>\n",
       "      <td>20.8634</td>\n",
       "      <td>1.504580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2043167_L_CC_1</td>\n",
       "      <td>2043167</td>\n",
       "      <td>Left</td>\n",
       "      <td>CC</td>\n",
       "      <td>1441.5069</td>\n",
       "      <td>5.9439</td>\n",
       "      <td>33.3823</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13.7715</td>\n",
       "      <td>0.993140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageName  DummyID BreastSide MammoView  BreastVolumeCm3  \\\n",
       "0   2036311_L_CC_1  2036311       Left        CC         551.8933   \n",
       "1  2036311_L_MLO_1  2036311       Left       MLO         638.1189   \n",
       "2   2036311_R_CC_1  2036311      Right        CC         468.4220   \n",
       "3  2036311_R_MLO_1  2036311      Right       MLO         712.3350   \n",
       "4   2043167_L_CC_1  2043167       Left        CC        1441.5069   \n",
       "\n",
       "   VolumetricBreastDensity  DenseAreaPercent  ComputedBreastThickness  \\\n",
       "0                   5.2457           67.1112                     62.0   \n",
       "1                  10.5883           92.3699                     63.0   \n",
       "2                   4.6236           39.2641                     56.0   \n",
       "3                   7.1716           85.2747                     70.0   \n",
       "4                   5.9439           33.3823                     70.0   \n",
       "\n",
       "   MaximumPercentDensityIn1Cm2Area  MaximumDenseVolumeIn1Cm2AreaInCm3  \n",
       "0                          16.3976                           1.047380  \n",
       "1                          25.2581                           1.639360  \n",
       "2                          14.5975                           0.842166  \n",
       "3                          20.8634                           1.504580  \n",
       "4                          13.7715                           0.993140  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPatientInfo(x):\n",
    "        \n",
    "    x = x.sort_values(['MammoView','BreastSide'])\n",
    "    \n",
    "    out =  np.concatenate(\n",
    "        [x.BreastVolumeCm3.values,\n",
    "         x.DenseAreaPercent.values\n",
    "        ])\n",
    "    \n",
    "    return out\n",
    "    \n",
    "\n",
    "\n",
    "out = vol.groupby('DummyID').apply(lambda x : extractPatientInfo(x))\n",
    "\n",
    "out = out.reset_index()\n",
    "\n",
    "temp = out[0].apply(pd.Series)\n",
    "\n",
    "out.drop(0, inplace = True, axis = 1)\n",
    "\n",
    "colNames = []\n",
    "varSelect = ['BreastVolumeCm3','DenseAreaPercent']\n",
    "\n",
    "for i in range(len(varSelect)):\n",
    "    \n",
    "    colNames.append(varSelect[i]+'L_CC')\n",
    "    colNames.append(varSelect[i]+'R_CC')\n",
    "    colNames.append(varSelect[i]+'L_MLO')\n",
    "    colNames.append(varSelect[i]+'R_MLO')\n",
    "    \n",
    "temp.columns = colNames\n",
    "\n",
    "vol = pd.concat([out, temp],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>BreastVolumeCm3L_CC</th>\n",
       "      <th>BreastVolumeCm3R_CC</th>\n",
       "      <th>BreastVolumeCm3L_MLO</th>\n",
       "      <th>BreastVolumeCm3R_MLO</th>\n",
       "      <th>DenseAreaPercentL_CC</th>\n",
       "      <th>DenseAreaPercentR_CC</th>\n",
       "      <th>DenseAreaPercentL_MLO</th>\n",
       "      <th>DenseAreaPercentR_MLO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2035300</td>\n",
       "      <td>1098.4721</td>\n",
       "      <td>1092.6537</td>\n",
       "      <td>1370.6361</td>\n",
       "      <td>1200.6639</td>\n",
       "      <td>39.8211</td>\n",
       "      <td>57.0010</td>\n",
       "      <td>43.3291</td>\n",
       "      <td>44.0651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2036311</td>\n",
       "      <td>551.8933</td>\n",
       "      <td>468.4220</td>\n",
       "      <td>638.1189</td>\n",
       "      <td>712.3350</td>\n",
       "      <td>67.1112</td>\n",
       "      <td>39.2641</td>\n",
       "      <td>92.3699</td>\n",
       "      <td>85.2747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2036695</td>\n",
       "      <td>605.6775</td>\n",
       "      <td>570.0239</td>\n",
       "      <td>689.7860</td>\n",
       "      <td>706.6826</td>\n",
       "      <td>71.8886</td>\n",
       "      <td>70.3447</td>\n",
       "      <td>66.2514</td>\n",
       "      <td>71.2205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2042193</td>\n",
       "      <td>654.6834</td>\n",
       "      <td>627.2421</td>\n",
       "      <td>676.7831</td>\n",
       "      <td>718.5041</td>\n",
       "      <td>87.1291</td>\n",
       "      <td>86.7084</td>\n",
       "      <td>89.3347</td>\n",
       "      <td>91.0358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2043167</td>\n",
       "      <td>1441.5069</td>\n",
       "      <td>1414.7118</td>\n",
       "      <td>1514.2860</td>\n",
       "      <td>1280.8693</td>\n",
       "      <td>33.3823</td>\n",
       "      <td>10.0514</td>\n",
       "      <td>14.2366</td>\n",
       "      <td>17.0593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DummyID  BreastVolumeCm3L_CC  BreastVolumeCm3R_CC  BreastVolumeCm3L_MLO  \\\n",
       "0  2035300            1098.4721            1092.6537             1370.6361   \n",
       "1  2036311             551.8933             468.4220              638.1189   \n",
       "2  2036695             605.6775             570.0239              689.7860   \n",
       "3  2042193             654.6834             627.2421              676.7831   \n",
       "4  2043167            1441.5069            1414.7118             1514.2860   \n",
       "\n",
       "   BreastVolumeCm3R_MLO  DenseAreaPercentL_CC  DenseAreaPercentR_CC  \\\n",
       "0             1200.6639               39.8211               57.0010   \n",
       "1              712.3350               67.1112               39.2641   \n",
       "2              706.6826               71.8886               70.3447   \n",
       "3              718.5041               87.1291               86.7084   \n",
       "4             1280.8693               33.3823               10.0514   \n",
       "\n",
       "   DenseAreaPercentL_MLO  DenseAreaPercentR_MLO  \n",
       "0                43.3291                44.0651  \n",
       "1                92.3699                85.2747  \n",
       "2                66.2514                71.2205  \n",
       "3                89.3347                91.0358  \n",
       "4                14.2366                17.0593  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "      <th>label</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4186820</td>\n",
       "      <td>FullRes/3/4186820_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4186820_R_MLO_1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76789629</td>\n",
       "      <td>FullRes/2/76789629_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>76789629_R_MLO_1</td>\n",
       "      <td>70.9</td>\n",
       "      <td>24.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75073273</td>\n",
       "      <td>FullRes/3/75073273_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>75073273_R_MLO_1</td>\n",
       "      <td>36.3</td>\n",
       "      <td>27.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75577074</td>\n",
       "      <td>FullRes/2/75577074_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>75577074_L_CC_1</td>\n",
       "      <td>73.1</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75577074</td>\n",
       "      <td>FullRes/2/75577074_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>75577074_L_CC_1</td>\n",
       "      <td>73.1</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DummyID                        filename  train  label         ImageName  \\\n",
       "0   4186820   FullRes/3/4186820_R_MLO_1.jpg  False      0   4186820_R_MLO_1   \n",
       "1  76789629  FullRes/2/76789629_R_MLO_1.jpg  False      1  76789629_R_MLO_1   \n",
       "2  75073273  FullRes/3/75073273_R_MLO_1.jpg  False      0  75073273_R_MLO_1   \n",
       "3  75577074   FullRes/2/75577074_L_CC_1.jpg  False      1   75577074_L_CC_1   \n",
       "4  75577074   FullRes/2/75577074_L_CC_1.jpg  False      1   75577074_L_CC_1   \n",
       "\n",
       "    Age   BMI  \n",
       "0  45.0  22.6  \n",
       "1  70.9  24.7  \n",
       "2  36.3  27.3  \n",
       "3  73.1  19.2  \n",
       "4  73.1  19.7  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainPatients = pd.unique(df.loc[df.train==False]['DummyID'])\n",
    "validPatients = pd.unique(df.loc[df.train==True]['DummyID'])\n",
    "\n",
    "dropList = []\n",
    "for i in range(len(trainPatients)):\n",
    "    d = df[df.DummyID == trainPatients[i]]\n",
    "    if len(d)!=4:\n",
    "        dropList.append(trainPatients[i])\n",
    "\n",
    "trainPatients = list(set(trainPatients).difference(set(dropList)))\n",
    "\n",
    "\n",
    "dropList = []\n",
    "for i in range(len(validPatients)):\n",
    "    d = df[df.DummyID == validPatients[i]]\n",
    "    if len(d)!=4:\n",
    "        dropList.append(validPatients[i])\n",
    "\n",
    "validPatients = list(set(validPatients).difference(set(dropList)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7029"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainPatients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1785"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validPatients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Patient Data Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data for 3719366\n",
      "Missing data for 3723710\n",
      "Missing data for 3708759\n",
      "Missing data for 3708932\n",
      "Missing data for 3710225\n",
      "Missing data for 3727080\n",
      "Missing data for 3711618\n",
      "Missing data for 3728125\n",
      "Missing data for 3728404\n",
      "Missing data for 3728425\n",
      "Missing data for 3728751\n",
      "Missing data for 3729021\n",
      "Missing data for 3715282\n",
      "Missing data for 3715638\n",
      "Missing data for 3715835\n",
      "Missing data for 3715907\n",
      "Missing data for 3716244\n",
      "Missing data for 3716653\n",
      "Missing data for 3716896\n",
      "Missing data for 3716934\n",
      "Missing data for 3718105\n",
      "Missing data for 3718223\n",
      "Missing data for 3718428\n"
     ]
    }
   ],
   "source": [
    "### Train data\n",
    "trainData = []\n",
    "trainLabel = []\n",
    "for i in range(len(trainPatients)):\n",
    "    \n",
    "    r = df[df.DummyID==trainPatients[i]]\n",
    "    try:\n",
    "        val =  np.concatenate([np.array([r.iloc[0]['Age'],r.iloc[0]['BMI']]) , vol[vol.DummyID==trainPatients[i]].iloc[0,1:].values])\n",
    "\n",
    "        trainData.append(val)\n",
    "        trainLabel.append(r.iloc[0]['label'])\n",
    "    except:\n",
    "        print(\"Missing data for {}\".format(trainPatients[i]))\n",
    "    \n",
    "trainData = np.array(trainData)\n",
    "trainLabel = np.array(trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data for 3727468\n",
      "Missing data for 3715236\n",
      "Missing data for 3715651\n",
      "Missing data for 3716856\n",
      "Missing data for 3708897\n"
     ]
    }
   ],
   "source": [
    "### Valid data\n",
    "validData = []\n",
    "validLabel = []\n",
    "for i in range(len(validPatients)):\n",
    "    \n",
    "    r = df[df.DummyID==validPatients[i]]\n",
    "    try:\n",
    "        val =  np.concatenate([np.array([r.iloc[0]['Age'],r.iloc[0]['BMI']]) , vol[vol.DummyID==validPatients[i]].iloc[0,1:].values])\n",
    "        \n",
    "        validData.append(val)\n",
    "        validLabel.append(r.iloc[0]['label'])\n",
    "    except:\n",
    "        print(\"Missing data for {}\".format(validPatients[i]))\n",
    "        \n",
    "    \n",
    "validData = np.array(validData)\n",
    "validLabel = np.array(validLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing missing imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "trainData = imputer.fit_transform(trainData)\n",
    "\n",
    "validData = imputer.transform(validData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfModel = RandomForestClassifier(n_estimators=300, max_depth=8)\n",
    "rfModel.fit(trainData, trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6415730337078651"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rfModel.predict(validData)\n",
    "accuracy_score(pred, validLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7109620325435341"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rfModel.predict(trainData)\n",
    "accuracy_score(pred, trainLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With CNN prediction inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score0</th>\n",
       "      <th>score1</th>\n",
       "      <th>predLabel</th>\n",
       "      <th>imageName</th>\n",
       "      <th>truthLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.893288</td>\n",
       "      <td>0.106712</td>\n",
       "      <td>0</td>\n",
       "      <td>4186820_R_MLO_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.992637</td>\n",
       "      <td>1</td>\n",
       "      <td>76789629_R_MLO_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.846092</td>\n",
       "      <td>0.153908</td>\n",
       "      <td>0</td>\n",
       "      <td>75073273_R_MLO_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049612</td>\n",
       "      <td>0.950388</td>\n",
       "      <td>1</td>\n",
       "      <td>75577074_L_CC_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.553521</td>\n",
       "      <td>0.446479</td>\n",
       "      <td>0</td>\n",
       "      <td>76671221_L_CC_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     score0    score1  predLabel         imageName  truthLabel\n",
       "0  0.893288  0.106712          0   4186820_R_MLO_1           0\n",
       "1  0.007363  0.992637          1  76789629_R_MLO_1           1\n",
       "2  0.846092  0.153908          0  75073273_R_MLO_1           0\n",
       "3  0.049612  0.950388          1   75577074_L_CC_1           1\n",
       "4  0.553521  0.446479          0   76671221_L_CC_1           0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading train data predictions\n",
    "trainPredDf = pd.read_csv('model10_1_TrainPredictions.csv')\n",
    "\n",
    "if 'imageName' in trainPredDf.columns:\n",
    "    trainPredDf.rename(columns={'imageName':'ImageName'},inplace=True)\n",
    "\n",
    "    \n",
    "trainPredDf['DummyID'] = trainPredDf.ImageName.apply(lambda x : int(x.split(\"_\")[0]))\n",
    "\n",
    "trainPredDf = pd.merge(trainPredDf, truth[['DummyID','BMI']], on='DummyID',how='left')\n",
    "    \n",
    "\n",
    "trainPredDf['train']=False\n",
    "predDf['train']=True\n",
    "\n",
    "#Combining test and train data predictions\n",
    "totalPredDf = pd.concat([predDf,trainPredDf])\n",
    "\n",
    "totalPredDf.head()\n",
    "\n",
    "totalPredDf['side'] = totalPredDf.ImageName.apply(lambda x : x[-6:] if \"CC\" in x else x[-7:] )\n",
    "\n",
    "\n",
    "\n",
    "def extractPatientPred(x):\n",
    "    \n",
    "    x = x.sort_values('side')\n",
    "    x = x.drop_duplicates('ImageName')\n",
    "    \n",
    "    return x.score1.values\n",
    "\n",
    "patientPred = totalPredDf.groupby('DummyID').apply(extractPatientPred)\n",
    "\n",
    "patientPred = patientPred.reset_index()\n",
    "\n",
    "temp = patientPred[0].apply(pd.Series)\n",
    "\n",
    "patientPred.drop(0, inplace = True, axis =1)\n",
    "\n",
    "patientPred = pd.concat([patientPred,temp], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2035300</td>\n",
       "      <td>0.823334</td>\n",
       "      <td>0.887951</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.878106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2036311</td>\n",
       "      <td>0.997292</td>\n",
       "      <td>0.997214</td>\n",
       "      <td>0.998432</td>\n",
       "      <td>0.949211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2036695</td>\n",
       "      <td>0.831547</td>\n",
       "      <td>0.831207</td>\n",
       "      <td>0.973570</td>\n",
       "      <td>0.799288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2042193</td>\n",
       "      <td>0.956624</td>\n",
       "      <td>0.956276</td>\n",
       "      <td>0.700152</td>\n",
       "      <td>0.755652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2043167</td>\n",
       "      <td>0.876202</td>\n",
       "      <td>0.784373</td>\n",
       "      <td>0.998109</td>\n",
       "      <td>0.920610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DummyID         0         1         2         3\n",
       "0  2035300  0.823334  0.887951  0.997800  0.878106\n",
       "1  2036311  0.997292  0.997214  0.998432  0.949211\n",
       "2  2036695  0.831547  0.831207  0.973570  0.799288\n",
       "3  2042193  0.956624  0.956276  0.700152  0.755652\n",
       "4  2043167  0.876202  0.784373  0.998109  0.920610"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patientPred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data for 3719366\n",
      "Missing data for 3723710\n",
      "Missing data for 3708759\n",
      "Missing data for 3708932\n",
      "Missing data for 3710225\n",
      "Missing data for 3727080\n",
      "Missing data for 3711618\n",
      "Missing data for 3728125\n",
      "Missing data for 3728404\n",
      "Missing data for 3728425\n",
      "Missing data for 3728751\n",
      "Missing data for 3729021\n",
      "Missing data for 3715282\n",
      "Missing data for 3715638\n",
      "Missing data for 3715835\n",
      "Missing data for 3715907\n",
      "Missing data for 3716244\n",
      "Missing data for 3716653\n",
      "Missing data for 3716896\n",
      "Missing data for 3716934\n",
      "Missing data for 3718105\n",
      "Missing data for 3718223\n",
      "Missing data for 3718428\n"
     ]
    }
   ],
   "source": [
    "### Train data\n",
    "trainData = []\n",
    "trainLabel = []\n",
    "for i in range(len(trainPatients)):\n",
    "    \n",
    "    \n",
    "    r = df[df.DummyID==trainPatients[i]]\n",
    "    r = r.sort_values('ImageName')\n",
    "    \n",
    "    try:\n",
    "        val =  np.array([r.iloc[0]['Age']] + [r.iloc[0]['BMI']])\n",
    "        \n",
    "        volVal = vol[vol.DummyID==trainPatients[i]].iloc[0,1:].values\n",
    "\n",
    "        predVal  = patientPred[patientPred.DummyID==trainPatients[i]].iloc[0]\n",
    "\n",
    "        val = np.concatenate([val, volVal, predVal])\n",
    "\n",
    "        trainData.append(val)   \n",
    "        trainLabel.append(r.iloc[0]['label'])\n",
    "    except:\n",
    "        print(\"Missing data for {}\".format(trainPatients[i]))\n",
    "    \n",
    "trainData = np.array(trainData)\n",
    "trainLabel = np.array(trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data for 3727468\n",
      "Missing data for 3715236\n",
      "Missing data for 3715651\n",
      "Missing data for 3716856\n",
      "Missing data for 3708897\n"
     ]
    }
   ],
   "source": [
    "### valid data\n",
    "validData = []\n",
    "validLabel = []\n",
    "for i in range(len(validPatients)):\n",
    "    \n",
    "    \n",
    "    r = df[df.DummyID==validPatients[i]]\n",
    "    r = r.sort_values('ImageName')\n",
    "    \n",
    "    try:\n",
    "        val =  np.array([r.iloc[0]['Age']] + [r.iloc[0]['BMI']])\n",
    "        \n",
    "        volVal = vol[vol.DummyID==validPatients[i]].iloc[0,1:].values\n",
    "\n",
    "        predVal  = patientPred[patientPred.DummyID==validPatients[i]].iloc[0]\n",
    "\n",
    "        val = np.concatenate([val, volVal, predVal])\n",
    "\n",
    "        validData.append(val)   \n",
    "        validLabel.append(r.iloc[0]['label'])\n",
    "    except:\n",
    "        print(\"Missing data for {}\".format(validPatients[i]))\n",
    "    \n",
    "validData = np.array(validData)\n",
    "validLabel = np.array(validLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing missing imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "trainData = imputer.fit_transform(trainData)\n",
    "\n",
    "validData = imputer.transform(validData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfModel = RandomForestClassifier(n_estimators=300, max_depth=6)\n",
    "rfModel.fit(trainData, trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8898876404494382"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rfModel.predict(validData)\n",
    "accuracy_score(pred, validLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584641735655153"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rfModel.predict(trainData)\n",
    "accuracy_score(pred, trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.003113, 0.011625, 0.003694, 0.003127, 0.00348 , 0.003058, 0.002917, 0.002843, 0.00243 , 0.00241 , 0.002687,\n",
       "       0.178223, 0.277924, 0.21563 , 0.286838])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfModel.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtModel = DecisionTreeClassifier(max_depth=4)\n",
    "dtModel.fit(trainData, trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8780898876404495"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dtModel.predict(validData)\n",
    "accuracy_score(pred, validLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9447616328860976"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dtModel.predict(trainData)\n",
    "accuracy_score(pred, trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train data\n",
    "trainData = []\n",
    "trainLabel = []\n",
    "for i in range(len(trainPatients)):\n",
    "    \n",
    "    r = df[df.DummyID==trainPatients[i]]\n",
    "    r = r.sort_values('ImageName')\n",
    "    \n",
    "    val =  [r.iloc[0]['Age']] + [r.iloc[0]['BMI']]\n",
    "    \n",
    "    imageData = []\n",
    "    for i in range(4):\n",
    "        feat  = list(np.load(os.path.join(trainFolder,r.iloc[i]['ImageName']+'.npy')).reshape(-1))\n",
    "        imageData = imageData + feat\n",
    "    \n",
    "    trainData.append(val+imageData)   #add val here for confounding vars\n",
    "    trainLabel.append(r.iloc[0]['label'])\n",
    "    \n",
    "trainData = np.array(trainData)\n",
    "trainLabel = np.array(trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### valid data\n",
    "validData = []\n",
    "validLabel = []\n",
    "for i in range(len(validPatients)):\n",
    "    \n",
    "    r = df[df.DummyID==validPatients[i]]\n",
    "    r = r.sort_values('ImageName')\n",
    "    \n",
    "    val =       [r.iloc[0]['Age']] + [r.iloc[0]['BMI']]\n",
    "    \n",
    "    imageData = []\n",
    "    for i in range(4):\n",
    "        feat  = list(np.load(os.path.join(validFolder,r.iloc[i]['ImageName']+'.npy')).reshape(-1))\n",
    "        imageData = imageData + feat\n",
    "    \n",
    "    validData.append(val +imageData )\n",
    "    validLabel.append(r.iloc[0]['label'])\n",
    "    \n",
    "validData = np.array(validData)\n",
    "validLabel = np.array(validLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MODELING\n",
    "\n",
    "\n",
    "rfModel = RandomForestClassifier(n_estimators=300, max_depth=12)\n",
    "rfModel.fit(trainData, trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8886198547215496"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rfModel.predict(validData)\n",
    "accuracy_score(pred, validLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8886315666041276"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(validLabel,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:07<00:00, 36.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8878928206000325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CV Testing\n",
    "\n",
    "scoreList = []\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    rfModel = RandomForestClassifier(n_estimators=300, max_depth=10)\n",
    "    rfModel.fit(trainData, trainLabel)\n",
    "    \n",
    "    pred = rfModel.predict(validData)\n",
    "    score = roc_auc_score(pred, validLabel)\n",
    "    \n",
    "    scoreList.append(score)\n",
    "    \n",
    "print(np.mean(scoreList))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Keras Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "inputShape = (2050,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(1024, activation='relu',input_shape=inputShape))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6693 samples, validate on 1652 samples\n",
      "Epoch 1/10\n",
      "6693/6693 [==============================] - 1s 207us/step - loss: 0.4066 - acc: 0.8921 - val_loss: 0.3446 - val_acc: 0.8801\n",
      "Epoch 2/10\n",
      "6693/6693 [==============================] - 1s 123us/step - loss: 0.2402 - acc: 0.9228 - val_loss: 0.3307 - val_acc: 0.8886\n",
      "Epoch 3/10\n",
      "6693/6693 [==============================] - 1s 124us/step - loss: 0.2030 - acc: 0.9355 - val_loss: 0.3084 - val_acc: 0.8898\n",
      "Epoch 4/10\n",
      "6693/6693 [==============================] - 1s 124us/step - loss: 0.1839 - acc: 0.9381 - val_loss: 0.3700 - val_acc: 0.8874\n",
      "Epoch 5/10\n",
      "6693/6693 [==============================] - 1s 123us/step - loss: 0.1763 - acc: 0.9398 - val_loss: 0.3109 - val_acc: 0.8959\n",
      "Epoch 6/10\n",
      "6693/6693 [==============================] - 1s 125us/step - loss: 0.1653 - acc: 0.9474 - val_loss: 0.3416 - val_acc: 0.8941\n",
      "Epoch 7/10\n",
      "6693/6693 [==============================] - 1s 125us/step - loss: 0.1504 - acc: 0.9501 - val_loss: 0.3879 - val_acc: 0.8953\n",
      "Epoch 8/10\n",
      "6693/6693 [==============================] - 1s 125us/step - loss: 0.1453 - acc: 0.9553 - val_loss: 0.3897 - val_acc: 0.8959\n",
      "Epoch 9/10\n",
      "6693/6693 [==============================] - 1s 123us/step - loss: 0.1366 - acc: 0.9571 - val_loss: 0.3897 - val_acc: 0.8929\n",
      "Epoch 10/10\n",
      "6693/6693 [==============================] - 1s 125us/step - loss: 0.1272 - acc: 0.9598 - val_loss: 0.4291 - val_acc: 0.8935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4841e1278>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainData, trainLabel,\n",
    "          batch_size=50,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(validData, validLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(1024, activation='relu',input_shape=inputShape))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6693 samples, validate on 1652 samples\n",
      "Epoch 1/10\n",
      "6693/6693 [==============================] - 1s 181us/step - loss: 0.3685 - acc: 0.9000 - val_loss: 0.3670 - val_acc: 0.8729\n",
      "Epoch 2/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.2278 - acc: 0.9269 - val_loss: 0.3679 - val_acc: 0.8820\n",
      "Epoch 3/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.2192 - acc: 0.9311 - val_loss: 0.3391 - val_acc: 0.8826\n",
      "Epoch 4/10\n",
      "6693/6693 [==============================] - 1s 112us/step - loss: 0.2052 - acc: 0.9362 - val_loss: 0.3450 - val_acc: 0.8874\n",
      "Epoch 5/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.1953 - acc: 0.9353 - val_loss: 0.3355 - val_acc: 0.8856\n",
      "Epoch 6/10\n",
      "6693/6693 [==============================] - 1s 109us/step - loss: 0.1718 - acc: 0.9432 - val_loss: 0.3712 - val_acc: 0.8935\n",
      "Epoch 7/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.1718 - acc: 0.9450 - val_loss: 0.4069 - val_acc: 0.8929\n",
      "Epoch 8/10\n",
      "6693/6693 [==============================] - 1s 111us/step - loss: 0.1733 - acc: 0.9471 - val_loss: 0.4052 - val_acc: 0.8904\n",
      "Epoch 9/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.1652 - acc: 0.9482 - val_loss: 0.4185 - val_acc: 0.8874\n",
      "Epoch 10/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.1654 - acc: 0.9504 - val_loss: 0.4520 - val_acc: 0.8850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc56ebd0518>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainData, trainLabel,\n",
    "          batch_size=50,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(validData, validLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for single images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "\n",
    "img = imread('/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/75218338_R_CC_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75218338</td>\n",
       "      <td>FullRes/3/75218338_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75145018</td>\n",
       "      <td>FullRes/2/75145018_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75913007</td>\n",
       "      <td>PennExtra_3500/75913007_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4632661</td>\n",
       "      <td>FullRes/2/4632661_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4011669</td>\n",
       "      <td>PennExtra_3500/4011669_FOR-PROCESSING_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DummyID                                           filename  train\n",
       "0  75218338                      FullRes/3/75218338_R_CC_1.jpg   True\n",
       "1  75145018                     FullRes/2/75145018_R_MLO_1.jpg   True\n",
       "2  75913007  PennExtra_3500/75913007_FOR-PROCESSING_L_CC_1.jpg  False\n",
       "3   4632661                       FullRes/2/4632661_R_CC_1.jpg   True\n",
       "4   4011669   PennExtra_3500/4011669_FOR-PROCESSING_R_CC_1.jpg  False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>withLargerDataset/75218338_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>withLargerDataset/75218338_R_CC_11.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>withLargerDataset/75218338_R_CC_12.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>withLargerDataset/75218338_R_CC_13.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>withLargerDataset/75218338_R_CC_14.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename  train\n",
       "0   withLargerDataset/75218338_R_CC_1.jpg  False\n",
       "1  withLargerDataset/75218338_R_CC_11.jpg  False\n",
       "2  withLargerDataset/75218338_R_CC_12.jpg   True\n",
       "3  withLargerDataset/75218338_R_CC_13.jpg  False\n",
       "4  withLargerDataset/75218338_R_CC_14.jpg   True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame([['withLargerDataset/75218338_R_CC_1.jpg',False],['withLargerDataset/75218338_R_CC_11.jpg',False],['withLargerDataset/75218338_R_CC_12.jpg',True],['withLargerDataset/75218338_R_CC_13.jpg',False],['withLargerDataset/75218338_R_CC_14.jpg',True]])\n",
    "df1.columns = ['filename','train']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function _normalize_batch at 0x7f82240b1950>, mean=tensor([0.7549, 0.7549, 0.7549]), std=tensor([0.3382, 0.3382, 0.3382]), do_x=True, do_y=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/santhosr/Documents/Birad/ProcessedData/./FullRes/3/75218338_R_CC_1.jpg'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.valid_ds.items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotImageData('75218338_R_CC_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=learn.predict(data.valid_ds.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0074, 0.9926]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0954,  2.8065]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.7549, 0.7549, 0.7549]), tensor([0.3382, 0.3382, 0.3382])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize\n",
    "\n",
    "tfms = torchvision.transforms.Compose([\n",
    "    Resize([256,256]),\n",
    "    ToTensor(),\n",
    "    Normalize(data.stats[0],data.stats[1])\n",
    "    \n",
    "    \n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = PIL.Image.open('/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/75218338_R_CC_1.jpg').convert('RGB')\n",
    "\n",
    "p = tfms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Creates the FastAI Dataset\n",
    "data = ImageItemList.from_df(df=df,path='/home/santhosr/Documents/Birad/ProcessedData/', cols='filename').split_from_df(col='train').label_from_func(getRaceLabel).transform(get_transforms(),size=256).databunch(bs=50).normalize()\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=data.valid_ds.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=data.one_item(data.valid_ds.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0,1:10,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0][0,0,1:10,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6960,  2.6999]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(p.unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6956,  2.6995]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(p.unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0954,  2.8065]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(e[0].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          ...,\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]],\n",
       "\n",
       "         [[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          ...,\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]],\n",
       "\n",
       "         [[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          ...,\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         ...,\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]],\n",
       "\n",
       "        [[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         ...,\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]],\n",
       "\n",
       "        [[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         ...,\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f81d40cefd0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.transpose(p.numpy(),[1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72472656"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(p.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1049395"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(p.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72472656"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(e[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.131105"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(e[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-fdd2b0be2489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/75218338_R_CC_1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    400\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_px\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.__class__.__name__} {tuple(self.shape)}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_px\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.__class__.__name__} {tuple(self.shape)}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m_repr_image_format\u001b[0;34m(self, format_str)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstr_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstr_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mimage2np\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimage2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m\"Convert from torch style `image` to numpy/matplotlib style.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'cpu'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m_repr_jpeg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.__class__.__name__} {tuple(self.shape)}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m_repr_image_format\u001b[0;34m(self, format_str)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstr_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstr_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mimage2np\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimage2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m\"Convert from torch style `image` to numpy/matplotlib style.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "Image('/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/75218338_R_CC_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Image in module fastai.vision.image:\n",
      "\n",
      "class Image(fastai.core.ItemBase)\n",
      " |  Support applying transforms to image data in `px`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Image\n",
      " |      fastai.core.ItemBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, px:torch.Tensor)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  affine(self, func:Callable[[Dict[str, Any]], torch.Tensor], *args, **kwargs) -> 'Image'\n",
      " |      Equivalent to `image.affine_mat = image.affine_mat @ func()`.\n",
      " |  \n",
      " |  apply_tfms(self, tfms:Union[Callable, Collection[Callable]], do_resolve:bool=True, xtra:Union[Dict[Callable, dict], NoneType]=None, size:Union[int, Tuple[int, int, int], NoneType]=None, resize_method:fastai.vision.image.ResizeMethod=<ResizeMethod.CROP: 1>, mult:int=32, padding_mode:str='reflection', mode:str='bilinear') -> torch.Tensor\n",
      " |      Apply all `tfms` to the `Image`, if `do_resolve` picks value for random args.\n",
      " |  \n",
      " |  brightness lambda x, *args, **kwargs\n",
      " |  \n",
      " |  clone(self)\n",
      " |      Mimic the behavior of torch.clone for `Image` objects.\n",
      " |  \n",
      " |  contrast lambda x, *args, **kwargs\n",
      " |  \n",
      " |  coord(self, func:Callable[[fastai.vision.image.FlowField, Collection[Any], Dict[str, Any]], torch.Tensor], *args, **kwargs) -> 'Image'\n",
      " |      Equivalent to `image.flow = func(image.flow, image.size)`.\n",
      " |  \n",
      " |  crop lambda x, *args, **kwargs\n",
      " |  \n",
      " |  crop_pad lambda x, *args, **kwargs\n",
      " |  \n",
      " |  dihedral lambda x, *args, **kwargs\n",
      " |  \n",
      " |  dihedral_affine lambda x, *args, **kwargs\n",
      " |  \n",
      " |  flip_affine lambda x, *args, **kwargs\n",
      " |  \n",
      " |  flip_lr lambda x, *args, **kwargs\n",
      " |  \n",
      " |  jitter lambda x, *args, **kwargs\n",
      " |  \n",
      " |  lighting(self, func:Callable[[torch.Tensor, Collection[Any], Dict[str, Any]], torch.Tensor], *args:Any, **kwargs:Any)\n",
      " |      Equivalent to `image = sigmoid(func(logit(image)))`.\n",
      " |  \n",
      " |  pad lambda x, *args, **kwargs\n",
      " |  \n",
      " |  perspective_warp lambda x, *args, **kwargs\n",
      " |  \n",
      " |  pixel(self, func:Callable[[torch.Tensor, Collection[Any], Dict[str, Any]], torch.Tensor], *args, **kwargs) -> 'Image'\n",
      " |      Equivalent to `image.px = func(image.px)`.\n",
      " |  \n",
      " |  refresh(self) -> None\n",
      " |      Apply any logit, flow, or affine transfers that have been sent to the `Image`.\n",
      " |  \n",
      " |  resize(self, size:Union[int, Tuple[int, int, int]]) -> 'Image'\n",
      " |      Resize the image to `size`, size can be a single int.\n",
      " |  \n",
      " |  rotate lambda x, *args, **kwargs\n",
      " |  \n",
      " |  save(self, fn:Union[pathlib.Path, str])\n",
      " |      Save the image to `fn`.\n",
      " |  \n",
      " |  set_sample(self, **kwargs) -> 'ImageBase'\n",
      " |      Set parameters that control how we `grid_sample` the image after transforms are applied.\n",
      " |  \n",
      " |  show(self, ax:matplotlib.axes._axes.Axes=None, figsize:tuple=(3, 3), title:Union[str, NoneType]=None, hide_axis:bool=True, cmap:str=None, y:Any=None, **kwargs)\n",
      " |      Show image on `ax` with `title`, using `cmap` if single-channel, overlaid with optional `y`\n",
      " |  \n",
      " |  skew lambda x, *args, **kwargs\n",
      " |  \n",
      " |  squish lambda x, *args, **kwargs\n",
      " |  \n",
      " |  symmetric_warp lambda x, *args, **kwargs\n",
      " |  \n",
      " |  tilt lambda x, *args, **kwargs\n",
      " |  \n",
      " |  zoom lambda x, *args, **kwargs\n",
      " |  \n",
      " |  zoom_squish lambda x, *args, **kwargs\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  affine_mat\n",
      " |      Get the affine matrix that will be applied by `refresh`.\n",
      " |  \n",
      " |  data\n",
      " |      Return this images pixels as a tensor.\n",
      " |  \n",
      " |  device\n",
      " |  \n",
      " |  flow\n",
      " |      Access the flow-field grid after applying queued affine transforms.\n",
      " |  \n",
      " |  logit_px\n",
      " |      Get logit(image.px).\n",
      " |  \n",
      " |  px\n",
      " |      Get the tensor pixel buffer.\n",
      " |  \n",
      " |  shape\n",
      " |  \n",
      " |  size\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from fastai.core.ItemBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class type in module builtins:\n",
      "\n",
      "class type(object)\n",
      " |  type(object_or_name, bases, dict)\n",
      " |  type(object) -> the object's type\n",
      " |  type(name, bases, dict) -> a new type\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, /, *args, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name, /)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(...)\n",
      " |      __dir__() -> list\n",
      " |      specialized __dir__ implementation for types\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __instancecheck__(...)\n",
      " |      __instancecheck__() -> bool\n",
      " |      check if an object is an instance\n",
      " |  \n",
      " |  __new__(*args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __prepare__(...)\n",
      " |      __prepare__() -> dict\n",
      " |      used to create the namespace for the class statement\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value, /)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      __sizeof__() -> int\n",
      " |      return memory consumption of the type object\n",
      " |  \n",
      " |  __subclasscheck__(...)\n",
      " |      __subclasscheck__() -> bool\n",
      " |      check if a class is a subclass\n",
      " |  \n",
      " |  __subclasses__(...)\n",
      " |      __subclasses__() -> list of immediate subclasses\n",
      " |  \n",
      " |  mro(...)\n",
      " |      mro() -> list\n",
      " |      return a type's method resolution order\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __abstractmethods__\n",
      " |  \n",
      " |  __dict__\n",
      " |  \n",
      " |  __text_signature__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __base__ = <class 'object'>\n",
      " |      The most base type\n",
      " |  \n",
      " |  __bases__ = (<class 'object'>,)\n",
      " |  \n",
      " |  __basicsize__ = 864\n",
      " |  \n",
      " |  __dictoffset__ = 264\n",
      " |  \n",
      " |  __flags__ = 2148291584\n",
      " |  \n",
      " |  __itemsize__ = 40\n",
      " |  \n",
      " |  __mro__ = (<class 'type'>, <class 'object'>)\n",
      " |  \n",
      " |  __weakrefoffset__ = 368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(type(Image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
