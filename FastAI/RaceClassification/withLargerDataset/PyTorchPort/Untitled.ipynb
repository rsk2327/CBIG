{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback import *\n",
    "from fastai.basic_train import *\n",
    "import torchvision.models as tmodels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.misc import imsave\n",
    "\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import torchvision\n",
    "from torch.nn import Sigmoid\n",
    "from torch import Tensor, LongTensor\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import Sequential\n",
    "from torchvision.models.resnet import resnet50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/santhosr/Documents/Birad/FastAI/RaceClassification/' )\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from birad import *\n",
    "from birad import setTruthFile, getRaceLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder1 = '/home/santhosr/Documents/Birad/ProcessedData/FullRes'\n",
    "truthFile1 = '/home/santhosr/Documents/Birad/birad_targetFile.csv'\n",
    "\n",
    "inputFolder2 = '/home/santhosr/Documents/Birad/ProcessedData/PennExtra_3500/'\n",
    "truthFile2 = '/home/santhosr/Documents/Birad/RaceDL_ExtraCaucasian.csv'\n",
    "\n",
    "df1 = pd.read_csv('/home/santhosr/Documents/Birad/birad_targetFile.csv')\n",
    "df1.drop(['PresIntentType','DBT'],inplace = True,axis=1)\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('/home/santhosr/Documents/Birad/RaceDL_ExtraCaucasian.csv')\n",
    "df2.Medview_Race = 'White'\n",
    "truth = pd.concat([df1,df2],sort=True)\n",
    "\n",
    "setTruthFile(truth)\n",
    "\n",
    "\n",
    "dfFile = \"/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/DataFile10.csv\"\n",
    "\n",
    "modelName = 'model_resnet50_id10_acc833_loss386'\n",
    "\n",
    "\n",
    "#Feature Directories\n",
    "trainFolder = '/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/Features/model9_2/train'\n",
    "\n",
    "validFolder = '/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/Features/model9_2/valid'\n",
    "\n",
    "df = pd.read_csv(dfFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "d = pd.concat([df[df.train==True].iloc[0:100], df[df.train==False].iloc[0:100], ])\n",
    "\n",
    "#Creates the FastAI Dataset\n",
    "data = ImageItemList.from_df(df=d,path='/home/santhosr/Documents/Birad/ProcessedData/', cols='filename').split_from_df(col='train').label_from_func(getRaceLabel).transform(get_transforms(),size=256).databunch(bs=50).normalize()\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (100 items)\n",
       "[Category 0, Category 1, Category 0, Category 1, Category 0]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData\n",
       "x: ImageItemList (100 items)\n",
       "[Image (3, 3328, 2560), Image (3, 4096, 3328), Image (3, 4096, 3328), Image (3, 3328, 2560), Image (3, 3328, 2560)]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (100 items)\n",
       "[Category 1, Category 1, Category 1, Category 0, Category 0]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData\n",
       "x: ImageItemList (100 items)\n",
       "[Image (3, 4096, 3328), Image (3, 4096, 3328), Image (3, 3328, 2560), Image (3, 4096, 3328), Image (3, 3328, 2560)]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData;\n",
       "\n",
       "Test: None, model=Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Lambda()\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f2e9803bf60>, metrics=[<function accuracy at 0x7f2e0c5bf378>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/santhosr/Documents/Birad/ProcessedData'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU(inplace)\n",
       "  (11): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace)\n",
       "  (20): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (24): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU(inplace)\n",
       "  (27): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (30): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (31): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (33): ReLU(inplace)\n",
       "  (34): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (38): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (40): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (42): ReLU(inplace)\n",
       "  (43): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (44): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (45): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (46): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (47): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (49): ReLU(inplace)\n",
       "  (50): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (51): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (52): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (54): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (56): ReLU(inplace)\n",
       "), Sequential(\n",
       "  (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (14): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): ReLU(inplace)\n",
       "  (16): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): ReLU(inplace)\n",
       "  (23): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (27): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): ReLU(inplace)\n",
       "  (30): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (34): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (35): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): ReLU(inplace)\n",
       "  (37): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (39): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (40): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (41): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (42): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (43): ReLU(inplace)\n",
       "  (44): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (48): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (50): ReLU(inplace)\n",
       "  (51): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (52): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (53): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (55): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (56): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (57): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (58): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (59): ReLU(inplace)\n",
       "  (60): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (62): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (64): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (66): ReLU(inplace)\n",
       "), Sequential(\n",
       "  (0): AdaptiveAvgPool2d(output_size=1)\n",
       "  (1): AdaptiveMaxPool2d(output_size=1)\n",
       "  (2): Lambda()\n",
       "  (3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Dropout(p=0.25)\n",
       "  (5): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Dropout(p=0.5)\n",
       "  (9): Linear(in_features=512, out_features=2, bias=True)\n",
       ")])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates the model architecture \n",
    "learn = create_cnn(data, tmodels.resnet50, metrics=accuracy,pretrained=True)\n",
    "\n",
    "learn.load('/home/santhosr/Documents/Birad/ProcessedData/models/'+modelName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fastAIModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fastAIModel, self).__init__()\n",
    "        \n",
    "    \n",
    "        self.body =  Sequential(*list(resnet50().children())[:-2])\n",
    "    \n",
    "        \n",
    "        self.head =     Sequential(\n",
    "                            AdaptiveConcatPool2d(), Flatten(),\n",
    "                            nn.BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), \n",
    "                            nn.Dropout(p=0.25), \n",
    "                            nn.Linear(in_features=4096, out_features=512, bias=True), \n",
    "                            nn.ReLU(inplace = True),\n",
    "                            nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), \n",
    "                            nn.Dropout(p=0.5), \n",
    "                            nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "                        )\n",
    "        \n",
    "        \n",
    "        self.total = nn.Sequential(self.body, self.head)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        x = self.total(x)\n",
    "        \n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = fastAIModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.total.load_state_dict(torch.load('/home/santhosr/Documents/Birad/ProcessedData/models/model_resnet50_id10_acc833_loss386.pth')['model'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on common matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0685,  0.5951]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones((1,3,224,224))\n",
    "\n",
    "\n",
    "learn.model.eval()\n",
    "learn.model(t.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8616, -1.6184]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand((1,3,224,224))\n",
    "\n",
    "learn.model.eval()\n",
    "learn.model(rand.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8616, -1.6184]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.valid_ds.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(img.data.dtype)\n",
    "img.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0057, 0.9943]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedImg = learn.data.one_item(data.valid_dl.x[0])[0]\n",
    "\n",
    "processedImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8241,  2.3344]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(processedImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0057, 0.9943]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax()(learn.model(processedImg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil2tensor(image,dtype):\n",
    "    \"Convert PIL style `image` array to torch style image tensor.\"\n",
    "    a = np.asarray(image)\n",
    "    if a.ndim==2 : a = np.expand_dims(a,2)\n",
    "    a = np.transpose(a, (1, 0, 2))\n",
    "    a = np.transpose(a, (2, 1, 0))\n",
    "    return torch.from_numpy(a.astype(dtype, copy=False) )\n",
    "\n",
    "filename = '/home/santhosr/Documents/Birad/ProcessedData/./FullRes/2/75048084_R_CC_1.jpg'\n",
    "\n",
    "x = PIL.Image.open(filename).convert('RGB')\n",
    "\n",
    "x = pil2tensor(x,np.float32)\n",
    "\n",
    "x.div_(255)   \n",
    "\n",
    "out = fastai.vision.Image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = data.one_item(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0057, 0.9943]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax()(learn.model(tp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil2tensor(image,dtype):\n",
    "    \"Convert PIL style `image` array to torch style image tensor.\"\n",
    "    a = np.asarray(image)\n",
    "    if a.ndim==2 : a = np.expand_dims(a,2)\n",
    "    a = np.transpose(a, (1, 0, 2))\n",
    "    a = np.transpose(a, (2, 1, 0))\n",
    "    return torch.from_numpy(a.astype(dtype, copy=False) )\n",
    "\n",
    "filename = '/home/santhosr/Documents/Birad/ProcessedData/./FullRes/2/75048084_R_CC_1.jpg'\n",
    "\n",
    "x = PIL.Image.open(filename).convert('RGB')\n",
    "\n",
    "x = pil2tensor(x,np.float32)\n",
    "\n",
    "x.div_(255)   \n",
    "\n",
    "out = fastai.vision.Image(x)\n",
    "\n",
    "ds = data.single_ds\n",
    "\n",
    "with ds.set_item(out):\n",
    "    batch =  data.one_batch(ds_type=DatasetType.Single, detach=False, denorm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0057, 0.9943]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax()(learn.model(batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import inspect\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <string>(1)<module>()->None\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()->ImageItemList.../ProcessedData\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(92)__getitem__()\n",
      "-> def __getitem__(self,idxs:int)->Any:\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(93)__getitem__()\n",
      "-> idxs = try_int(idxs)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(94)__getitem__()\n",
      "-> if isinstance(idxs, numbers.Integral): return self.get(idxs)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/abc.py(180)__instancecheck__()\n",
      "-> def __instancecheck__(cls, instance):\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/abc.py(183)__instancecheck__()\n",
      "-> subclass = instance.__class__\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/abc.py(184)__instancecheck__()\n",
      "-> if subclass in cls._abc_cache:\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/abc.py(185)__instancecheck__()\n",
      "-> return True\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/abc.py(185)__instancecheck__()->True\n",
      "-> return True\n",
      "(Pdb) n\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/vision/data.py(264)get()\n",
      "-> def get(self, i):\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/vision/data.py(265)get()\n",
      "-> fn = super().get(i)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/vision/data.py(266)get()\n",
      "-> res = self.open(fn)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/vision/data.py(267)get()\n",
      "-> self.sizes[i] = res.size\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/vision/data.py(268)get()\n",
      "-> return res\n",
      "(Pdb) s\n",
      "--Return--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/vision/data.py(268)get()->Image (3, 4096, 3328)\n",
      "-> return res\n",
      "(Pdb) s\n",
      "--Return--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(94)__getitem__()->Image (3, 4096, 3328)\n",
      "-> if isinstance(idxs, numbers.Integral): return self.get(idxs)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(259)predict()\n",
      "-> def predict(self, item:ItemBase, **kwargs):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(261)predict()\n",
      "-> self.callbacks.append(RecordOnCPU())\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(262)predict()\n",
      "-> batch = self.data.one_item(item)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(150)one_item()\n",
      "-> def one_item(self, item, detach:bool=False, denorm:bool=False):\n",
      "(Pdb) ll\n",
      "150  ->\t    def one_item(self, item, detach:bool=False, denorm:bool=False):\n",
      "151  \t        \"Get `item` into a batch. Optionally `detach` and `denorm`.\"\n",
      "152  \t        ds = self.single_ds\n",
      "153  \t        with ds.set_item(item):\n",
      "154  \t            return self.one_batch(ds_type=DatasetType.Single, detach=detach, denorm=denorm)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(152)one_item()\n",
      "-> ds = self.single_ds\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(153)one_item()\n",
      "-> with ds.set_item(item):\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(154)one_item()\n",
      "-> return self.one_batch(ds_type=DatasetType.Single, detach=detach, denorm=denorm)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(136)one_batch()\n",
      "-> def one_batch(self, ds_type:DatasetType=DatasetType.Train, detach:bool=True, denorm:bool=True, cpu:bool=True)->Collection[Tensor]:\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(138)one_batch()\n",
      "-> dl = self.dl(ds_type)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(139)one_batch()\n",
      "-> w = self.num_workers\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(140)one_batch()\n",
      "-> self.num_workers = 0\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(141)one_batch()\n",
      "-> try:     x,y = next(iter(dl))\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(68)__iter__()\n",
      "-> def __iter__(self):\n",
      "(Pdb) ll\n",
      " 68  ->\t    def __iter__(self):\n",
      " 69  \t        \"Process and returns items from `DataLoader`.\"\n",
      " 70  \t        for b in self.dl: yield self.proc_batch(b)\n",
      "(Pdb) p len(self.dl)\n",
      "1\n",
      "(Pdb) p self.proc_batch(self.dl[0])\n",
      "*** TypeError: 'DataLoader' object does not support indexing\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(70)__iter__()\n",
      "-> for b in self.dl: yield self.proc_batch(b)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(818)__iter__()\n",
      "-> def __iter__(self):\n",
      "(Pdb) ll\n",
      "818  ->\t    def __iter__(self):\n",
      "819  \t        return _DataLoaderIter(self)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(819)__iter__()\n",
      "-> return _DataLoaderIter(self)\n",
      "(Pdb) ll\n",
      "818  \t    def __iter__(self):\n",
      "819  ->\t        return _DataLoaderIter(self)\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(819)__iter__()-><torch.utils....x7f473d742358>\n",
      "-> return _DataLoaderIter(self)\n",
      "(Pdb) ll\n",
      "818  \t    def __iter__(self):\n",
      "819  ->\t        return _DataLoaderIter(self)\n",
      "(Pdb) n\n",
      "--Call--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(612)__next__()\n",
      "-> def __next__(self):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(613)__next__()\n",
      "-> if self.num_workers == 0:  # same-process loading\n",
      "(Pdb) ll\n",
      "612  \t    def __next__(self):\n",
      "613  ->\t        if self.num_workers == 0:  # same-process loading\n",
      "614  \t            indices = next(self.sample_iter)  # may raise StopIteration\n",
      "615  \t            batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "616  \t            if self.pin_memory:\n",
      "617  \t                batch = pin_memory_batch(batch)\n",
      "618  \t            return batch\n",
      "619  \t\n",
      "620  \t        # check if the next sample has already been generated\n",
      "621  \t        if self.rcvd_idx in self.reorder_dict:\n",
      "622  \t            batch = self.reorder_dict.pop(self.rcvd_idx)\n",
      "623  \t            return self._process_next_batch(batch)\n",
      "624  \t\n",
      "625  \t        if self.batches_outstanding == 0:\n",
      "626  \t            self._shutdown_workers()\n",
      "627  \t            raise StopIteration\n",
      "628  \t\n",
      "629  \t        while True:\n",
      "630  \t            assert (not self.shutdown and self.batches_outstanding > 0)\n",
      "631  \t            idx, batch = self._get_batch()\n",
      "632  \t            self.batches_outstanding -= 1\n",
      "633  \t            if idx != self.rcvd_idx:\n",
      "634  \t                # store out-of-order samples\n",
      "635  \t                self.reorder_dict[idx] = batch\n",
      "636  \t                continue\n",
      "637  \t            return self._process_next_batch(batch)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(614)__next__()\n",
      "-> indices = next(self.sample_iter)  # may raise StopIteration\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(615)__next__()\n",
      "-> batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(616)__next__()\n",
      "-> if self.pin_memory:\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(618)__next__()\n",
      "-> return batch\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(618)__next__()->[tensor([[[[0....0, 1.0000]]]]), tensor([0])]\n",
      "-> return batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) ll\n",
      "612  \t    def __next__(self):\n",
      "613  \t        if self.num_workers == 0:  # same-process loading\n",
      "614  \t            indices = next(self.sample_iter)  # may raise StopIteration\n",
      "615  \t            batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "616  \t            if self.pin_memory:\n",
      "617  \t                batch = pin_memory_batch(batch)\n",
      "618  ->\t            return batch\n",
      "619  \t\n",
      "620  \t        # check if the next sample has already been generated\n",
      "621  \t        if self.rcvd_idx in self.reorder_dict:\n",
      "622  \t            batch = self.reorder_dict.pop(self.rcvd_idx)\n",
      "623  \t            return self._process_next_batch(batch)\n",
      "624  \t\n",
      "625  \t        if self.batches_outstanding == 0:\n",
      "626  \t            self._shutdown_workers()\n",
      "627  \t            raise StopIteration\n",
      "628  \t\n",
      "629  \t        while True:\n",
      "630  \t            assert (not self.shutdown and self.batches_outstanding > 0)\n",
      "631  \t            idx, batch = self._get_batch()\n",
      "632  \t            self.batches_outstanding -= 1\n",
      "633  \t            if idx != self.rcvd_idx:\n",
      "634  \t                # store out-of-order samples\n",
      "635  \t                self.reorder_dict[idx] = batch\n",
      "636  \t                continue\n",
      "637  \t            return self._process_next_batch(batch)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(62)proc_batch()\n",
      "-> def proc_batch(self,b:Tensor)->Tensor:\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(64)proc_batch()\n",
      "-> b = to_device(b, self.device)\n",
      "(Pdb) p self.device\n",
      "device(type='cuda')\n",
      "(Pdb) self b\n",
      "*** SyntaxError: invalid syntax\n",
      "(Pdb) p b\n",
      "[tensor([[[[0.1570, 0.1570, 0.1554,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1598, 0.1594, 0.1585,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1565, 0.1548, 0.1573,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.6956, 0.6539, 0.7245,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7358, 0.7329, 0.7599,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8166, 0.7561, 0.7874,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.1570, 0.1570, 0.1554,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1598, 0.1594, 0.1585,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1565, 0.1548, 0.1573,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.6956, 0.6539, 0.7245,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7358, 0.7329, 0.7599,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8166, 0.7561, 0.7874,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.1570, 0.1570, 0.1554,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1598, 0.1594, 0.1585,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1565, 0.1548, 0.1573,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.6956, 0.6539, 0.7245,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7358, 0.7329, 0.7599,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8166, 0.7561, 0.7874,  ..., 1.0000, 1.0000, 1.0000]]]]), tensor([0])]\n",
      "(Pdb) p b.shape\n",
      "*** AttributeError: 'list' object has no attribute 'shape'\n",
      "(Pdb) p b[0].shape\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(Pdb) p self.tfms\n",
      "[functools.partial(<function _normalize_batch at 0x7f4751c2cd08>, mean=tensor([0.7601, 0.7601, 0.7601]), std=tensor([0.3307, 0.3307, 0.3307]), do_x=True, do_y=False)]\n",
      "(Pdb) quit\n"
     ]
    }
   ],
   "source": [
    "pdb.run('learn.predict(data.valid_dl.x[1])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <string>(1)<module>()->None\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()->ImageItemList.../ProcessedData\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(92)__getitem__()\n",
      "-> def __getitem__(self,idxs:int)->Any:\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(93)__getitem__()\n",
      "-> idxs = try_int(idxs)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(94)__getitem__()\n",
      "-> if isinstance(idxs, numbers.Integral): return self.get(idxs)\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(94)__getitem__()->Image (3, 4096, 3328)\n",
      "-> if isinstance(idxs, numbers.Integral): return self.get(idxs)\n",
      "(Pdb) n\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(259)predict()\n",
      "-> def predict(self, item:ItemBase, **kwargs):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(261)predict()\n",
      "-> self.callbacks.append(RecordOnCPU())\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(262)predict()\n",
      "-> batch = self.data.one_item(item)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(150)one_item()\n",
      "-> def one_item(self, item, detach:bool=False, denorm:bool=False):\n",
      "(Pdb) p item\n",
      "Image (3, 4096, 3328)\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(152)one_item()\n",
      "-> ds = self.single_ds\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(153)one_item()\n",
      "-> with ds.set_item(item):\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(154)one_item()\n",
      "-> return self.one_batch(ds_type=DatasetType.Single, detach=detach, denorm=denorm)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(136)one_batch()\n",
      "-> def one_batch(self, ds_type:DatasetType=DatasetType.Train, detach:bool=True, denorm:bool=True, cpu:bool=True)->Collection[Tensor]:\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(138)one_batch()\n",
      "-> dl = self.dl(ds_type)\n",
      "(Pdb) p dl\n",
      "*** NameError: name 'dl' is not defined\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(119)dl()\n",
      "-> def dl(self, ds_type:DatasetType=DatasetType.Valid)->DeviceDataLoader:\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(122)dl()\n",
      "-> return (self.train_dl if ds_type == DatasetType.Train else\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(123)dl()\n",
      "-> self.test_dl if ds_type == DatasetType.Test else\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(124)dl()\n",
      "-> self.valid_dl if ds_type == DatasetType.Valid else\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(125)dl()\n",
      "-> self.single_dl if ds_type == DatasetType.Single else\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(125)dl()->DeviceDataLoa...7f47585e91e0>)\n",
      "-> self.single_dl if ds_type == DatasetType.Single else\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(139)one_batch()\n",
      "-> w = self.num_workers\n",
      "(Pdb) ll\n",
      "136  \t    def one_batch(self, ds_type:DatasetType=DatasetType.Train, detach:bool=True, denorm:bool=True, cpu:bool=True)->Collection[Tensor]:\n",
      "137  \t        \"Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.\"\n",
      "138  \t        dl = self.dl(ds_type)\n",
      "139  ->\t        w = self.num_workers\n",
      "140  \t        self.num_workers = 0\n",
      "141  \t        try:     x,y = next(iter(dl))\n",
      "142  \t        finally: self.num_workers = w\n",
      "143  \t        if detach: x,y = to_detach(x,cpu=cpu),to_detach(y,cpu=cpu)\n",
      "144  \t        norm = getattr(self,'norm',False)\n",
      "145  \t        if denorm and norm:\n",
      "146  \t            x = self.denorm(x)\n",
      "147  \t            if norm.keywords.get('do_y',False): y = self.denorm(y, do_x=True)\n",
      "148  \t        return x,y\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(140)one_batch()\n",
      "-> self.num_workers = 0\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(141)one_batch()\n",
      "-> try:     x,y = next(iter(dl))\n",
      "(Pdb) p dl\n",
      "DeviceDataLoader(dl=<torch.utils.data.dataloader.DataLoader object at 0x7f473e4b3240>, device=device(type='cuda'), tfms=[functools.partial(<function _normalize_batch at 0x7f4751c2cd08>, mean=tensor([0.7601, 0.7601, 0.7601]), std=tensor([0.3307, 0.3307, 0.3307]), do_x=True, do_y=False)], collate_fn=<function data_collate at 0x7f47585e91e0>)\n",
      "(Pdb) p dl.__class__\n",
      "<class 'fastai.basic_data.DeviceDataLoader'>\n",
      "(Pdb) p dl.tfms\n",
      "[functools.partial(<function _normalize_batch at 0x7f4751c2cd08>, mean=tensor([0.7601, 0.7601, 0.7601]), std=tensor([0.3307, 0.3307, 0.3307]), do_x=True, do_y=False)]\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(68)__iter__()\n",
      "-> def __iter__(self):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(70)__iter__()\n",
      "-> for b in self.dl: yield self.proc_batch(b)\n",
      "(Pdb) p self.dl[0]\n",
      "*** TypeError: 'DataLoader' object does not support indexing\n",
      "(Pdb) p self.dl.x[0]\n",
      "Image (3, 4096, 3328)\n",
      "(Pdb) p self.proc_batch(self.dl.x[0])\n",
      "*** AttributeError: 'Image' object has no attribute 'to'\n",
      "(Pdb) p self.proc_batch(self.dl.x[0].data)\n",
      "*** ValueError: too many values to unpack (expected 2)\n",
      "(Pdb) ll\n",
      " 68  \t    def __iter__(self):\n",
      " 69  \t        \"Process and returns items from `DataLoader`.\"\n",
      " 70  ->\t        for b in self.dl: yield self.proc_batch(b)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(818)__iter__()\n",
      "-> def __iter__(self):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(819)__iter__()\n",
      "-> return _DataLoaderIter(self)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(518)__init__()\n",
      "-> def __init__(self, loader):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(519)__init__()\n",
      "-> self.dataset = loader.dataset\n",
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(520)__init__()\n",
      "-> self.collate_fn = loader.collate_fn\n",
      "(Pdb) p loader.collate_fn\n",
      "<function data_collate at 0x7f47585e91e0>\n",
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(521)__init__()\n",
      "-> self.batch_sampler = loader.batch_sampler\n",
      "(Pdb) p help(self.collate_fn)\n",
      "Help on function data_collate in module fastai.torch_core:\n",
      "\n",
      "data_collate(batch:Collection[Union[torch.Tensor, fastai.core.ItemBase, _ForwardRef('ItemsList'), float, int]]) -> torch.Tensor\n",
      "    Convert `batch` items to tensor data.\n",
      "\n",
      "None\n",
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(522)__init__()\n",
      "-> self.num_workers = loader.num_workers\n",
      "(Pdb) ll\n",
      "518  \t    def __init__(self, loader):\n",
      "519  \t        self.dataset = loader.dataset\n",
      "520  \t        self.collate_fn = loader.collate_fn\n",
      "521  \t        self.batch_sampler = loader.batch_sampler\n",
      "522  ->\t        self.num_workers = loader.num_workers\n",
      "523  \t        self.pin_memory = loader.pin_memory and torch.cuda.is_available()\n",
      "524  \t        self.timeout = loader.timeout\n",
      "525  \t\n",
      "526  \t        self.sample_iter = iter(self.batch_sampler)\n",
      "527  \t\n",
      "528  \t        base_seed = torch.LongTensor(1).random_().item()\n",
      "529  \t\n",
      "530  \t        if self.num_workers > 0:\n",
      "531  \t            self.worker_init_fn = loader.worker_init_fn\n",
      "532  \t            self.worker_queue_idx = 0\n",
      "533  \t            self.worker_result_queue = multiprocessing.Queue()\n",
      "534  \t            self.batches_outstanding = 0\n",
      "535  \t            self.worker_pids_set = False\n",
      "536  \t            self.shutdown = False\n",
      "537  \t            self.send_idx = 0\n",
      "538  \t            self.rcvd_idx = 0\n",
      "539  \t            self.reorder_dict = {}\n",
      "540  \t            self.done_event = multiprocessing.Event()\n",
      "541  \t\n",
      "542  \t            self.index_queues = []\n",
      "543  \t            self.workers = []\n",
      "544  \t            for i in range(self.num_workers):\n",
      "545  \t                index_queue = multiprocessing.Queue()\n",
      "546  \t                index_queue.cancel_join_thread()\n",
      "547  \t                w = multiprocessing.Process(\n",
      "548  \t                    target=_worker_loop,\n",
      "549  \t                    args=(self.dataset, index_queue,\n",
      "550  \t                          self.worker_result_queue, self.done_event,\n",
      "551  \t                          self.collate_fn, base_seed + i,\n",
      "552  \t                          self.worker_init_fn, i))\n",
      "553  \t                w.daemon = True\n",
      "554  \t                # NB: Process.start() actually take some time as it needs to\n",
      "555  \t                #     start a process and pass the arguments over via a pipe.\n",
      "556  \t                #     Therefore, we only add a worker to self.workers list after\n",
      "557  \t                #     it started, so that we do not call .join() if program dies\n",
      "558  \t                #     before it starts, and __del__ tries to join but will get:\n",
      "559  \t                #     AssertionError: can only join a started process.\n",
      "560  \t                w.start()\n",
      "561  \t                self.index_queues.append(index_queue)\n",
      "562  \t                self.workers.append(w)\n",
      "563  \t\n",
      "564  \t            if self.pin_memory:\n",
      "565  \t                self.data_queue = queue.Queue()\n",
      "566  \t                pin_memory_thread = threading.Thread(\n",
      "567  \t                    target=_pin_memory_loop,\n",
      "568  \t                    args=(self.worker_result_queue, self.data_queue,\n",
      "569  \t                          torch.cuda.current_device(), self.done_event))\n",
      "570  \t                pin_memory_thread.daemon = True\n",
      "571  \t                pin_memory_thread.start()\n",
      "572  \t                # Similar to workers (see comment above), we only register\n",
      "573  \t                # pin_memory_thread once it is started.\n",
      "574  \t                self.pin_memory_thread = pin_memory_thread\n",
      "575  \t            else:\n",
      "576  \t                self.data_queue = self.worker_result_queue\n",
      "577  \t\n",
      "578  \t            _update_worker_pids(id(self), tuple(w.pid for w in self.workers))\n",
      "579  \t            _set_SIGCHLD_handler()\n",
      "580  \t            self.worker_pids_set = True\n",
      "581  \t\n",
      "582  \t            # prime the prefetch loop\n",
      "583  \t            for _ in range(2 * self.num_workers):\n",
      "584  \t                self._put_indices()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(523)__init__()\n",
      "-> self.pin_memory = loader.pin_memory and torch.cuda.is_available()\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(524)__init__()\n",
      "-> self.timeout = loader.timeout\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(526)__init__()\n",
      "-> self.sample_iter = iter(self.batch_sampler)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(528)__init__()\n",
      "-> base_seed = torch.LongTensor(1).random_().item()\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(530)__init__()\n",
      "-> if self.num_workers > 0:\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(530)__init__()->None\n",
      "-> if self.num_workers > 0:\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(819)__iter__()-><torch.utils....x7f473d7487b8>\n",
      "-> return _DataLoaderIter(self)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(612)__next__()\n",
      "-> def __next__(self):\n",
      "(Pdb) ll\n",
      "612  ->\t    def __next__(self):\n",
      "613  \t        if self.num_workers == 0:  # same-process loading\n",
      "614  \t            indices = next(self.sample_iter)  # may raise StopIteration\n",
      "615  \t            batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "616  \t            if self.pin_memory:\n",
      "617  \t                batch = pin_memory_batch(batch)\n",
      "618  \t            return batch\n",
      "619  \t\n",
      "620  \t        # check if the next sample has already been generated\n",
      "621  \t        if self.rcvd_idx in self.reorder_dict:\n",
      "622  \t            batch = self.reorder_dict.pop(self.rcvd_idx)\n",
      "623  \t            return self._process_next_batch(batch)\n",
      "624  \t\n",
      "625  \t        if self.batches_outstanding == 0:\n",
      "626  \t            self._shutdown_workers()\n",
      "627  \t            raise StopIteration\n",
      "628  \t\n",
      "629  \t        while True:\n",
      "630  \t            assert (not self.shutdown and self.batches_outstanding > 0)\n",
      "631  \t            idx, batch = self._get_batch()\n",
      "632  \t            self.batches_outstanding -= 1\n",
      "633  \t            if idx != self.rcvd_idx:\n",
      "634  \t                # store out-of-order samples\n",
      "635  \t                self.reorder_dict[idx] = batch\n",
      "636  \t                continue\n",
      "637  \t            return self._process_next_batch(batch)\n",
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(613)__next__()\n",
      "-> if self.num_workers == 0:  # same-process loading\n",
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(614)__next__()\n",
      "-> indices = next(self.sample_iter)  # may raise StopIteration\n",
      "(Pdb) p self.sample_iter\n",
      "<generator object BatchSampler.__iter__ at 0x7f473d734200>\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/sampler.py(158)__iter__()\n",
      "-> def __iter__(self):\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/sampler.py(159)__iter__()\n",
      "-> batch = []\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/sampler.py(160)__iter__()\n",
      "-> for idx in self.sampler:\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/sampler.py(161)__iter__()\n",
      "-> batch.append(idx)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/sampler.py(162)__iter__()\n",
      "-> if len(batch) == self.batch_size:\n",
      "(Pdb) n\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/sampler.py(163)__iter__()\n",
      "-> yield batch\n",
      "(Pdb) n\n",
      "GeneratorExit\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(70)__iter__()\n",
      "-> for b in self.dl: yield self.proc_batch(b)\n",
      "(Pdb) ll\n",
      " 68  \t    def __iter__(self):\n",
      " 69  \t        \"Process and returns items from `DataLoader`.\"\n",
      " 70  ->\t        for b in self.dl: yield self.proc_batch(b)\n",
      "(Pdb) p b\n",
      "[tensor([[[[0.1570, 0.1570, 0.1554,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1598, 0.1594, 0.1585,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1565, 0.1548, 0.1573,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.6956, 0.6539, 0.7245,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7358, 0.7329, 0.7599,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8166, 0.7561, 0.7874,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.1570, 0.1570, 0.1554,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1598, 0.1594, 0.1585,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1565, 0.1548, 0.1573,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.6956, 0.6539, 0.7245,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7358, 0.7329, 0.7599,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8166, 0.7561, 0.7874,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.1570, 0.1570, 0.1554,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1598, 0.1594, 0.1585,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1565, 0.1548, 0.1573,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.6956, 0.6539, 0.7245,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7358, 0.7329, 0.7599,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8166, 0.7561, 0.7874,  ..., 1.0000, 1.0000, 1.0000]]]]), tensor([0])]\n",
      "(Pdb) p b.shape\n",
      "*** AttributeError: 'list' object has no attribute 'shape'\n",
      "(Pdb) p b[0].shape\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(Pdb) p type(dl)\n",
      "*** NameError: name 'dl' is not defined\n",
      "(Pdb) ll\n",
      " 68  \t    def __iter__(self):\n",
      " 69  \t        \"Process and returns items from `DataLoader`.\"\n",
      " 70  ->\t        for b in self.dl: yield self.proc_batch(b)\n",
      "(Pdb) p type(self.dl)\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "(Pdb) p self.dl.x[0]\n",
      "Image (3, 4096, 3328)\n",
      "(Pdb) p next(iter(self.dl))\n",
      "[tensor([[[[0.1570, 0.1570, 0.1554,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1598, 0.1594, 0.1585,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1565, 0.1548, 0.1573,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.6956, 0.6539, 0.7245,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7358, 0.7329, 0.7599,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8166, 0.7561, 0.7874,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.1570, 0.1570, 0.1554,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1598, 0.1594, 0.1585,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1565, 0.1548, 0.1573,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.6956, 0.6539, 0.7245,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7358, 0.7329, 0.7599,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8166, 0.7561, 0.7874,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.1570, 0.1570, 0.1554,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1598, 0.1594, 0.1585,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1565, 0.1548, 0.1573,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.6956, 0.6539, 0.7245,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.7358, 0.7329, 0.7599,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8166, 0.7561, 0.7874,  ..., 1.0000, 1.0000, 1.0000]]]]), tensor([0])]\n",
      "(Pdb) p self.dl\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f473e4b3240>\n",
      "(Pdb) quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object DeviceDataLoader.__iter__ at 0x7f473d59f0a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py\", line 70, in __iter__\n",
      "    for b in self.dl: yield self.proc_batch(b)\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/bdb.py\", line 57, in trace_dispatch\n",
      "    return self.dispatch_exception(frame, arg)\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/bdb.py\", line 122, in dispatch_exception\n",
      "    if self.quitting: raise BdbQuit\n",
      "bdb.BdbQuit: \n"
     ]
    }
   ],
   "source": [
    "pdb.run('learn.predict(data.valid_dl.x[1])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <string>(1)<module>()->None\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "(Pdb) n\n",
      "--Return--\n",
      "(Pdb) \n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(35)__getattr__()->ImageItemList.../ProcessedData\n",
      "-> def __getattr__(self,k:str)->Any: return getattr(self.dl, k)\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(92)__getitem__()\n",
      "-> def __getitem__(self,idxs:int)->Any:\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(93)__getitem__()\n",
      "-> idxs = try_int(idxs)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(94)__getitem__()\n",
      "-> if isinstance(idxs, numbers.Integral): return self.get(idxs)\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/data_block.py(94)__getitem__()->Image (3, 4096, 3328)\n",
      "-> if isinstance(idxs, numbers.Integral): return self.get(idxs)\n",
      "(Pdb) n\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(259)predict()\n",
      "-> def predict(self, item:ItemBase, **kwargs):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(261)predict()\n",
      "-> self.callbacks.append(RecordOnCPU())\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_train.py(262)predict()\n",
      "-> batch = self.data.one_item(item)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(150)one_item()\n",
      "-> def one_item(self, item, detach:bool=False, denorm:bool=False):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(152)one_item()\n",
      "-> ds = self.single_ds\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(153)one_item()\n",
      "-> with ds.set_item(item):\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(154)one_item()\n",
      "-> return self.one_batch(ds_type=DatasetType.Single, detach=detach, denorm=denorm)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(136)one_batch()\n",
      "-> def one_batch(self, ds_type:DatasetType=DatasetType.Train, detach:bool=True, denorm:bool=True, cpu:bool=True)->Collection[Tensor]:\n",
      "(Pdb) ll\n",
      "136  ->\t    def one_batch(self, ds_type:DatasetType=DatasetType.Train, detach:bool=True, denorm:bool=True, cpu:bool=True)->Collection[Tensor]:\n",
      "137  \t        \"Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.\"\n",
      "138  \t        dl = self.dl(ds_type)\n",
      "139  \t        w = self.num_workers\n",
      "140  \t        self.num_workers = 0\n",
      "141  \t        try:     x,y = next(iter(dl))\n",
      "142  \t        finally: self.num_workers = w\n",
      "143  \t        if detach: x,y = to_detach(x,cpu=cpu),to_detach(y,cpu=cpu)\n",
      "144  \t        norm = getattr(self,'norm',False)\n",
      "145  \t        if denorm and norm:\n",
      "146  \t            x = self.denorm(x)\n",
      "147  \t            if norm.keywords.get('do_y',False): y = self.denorm(y, do_x=True)\n",
      "148  \t        return x,y\n",
      "(Pdb) p ds_type\n",
      "<DatasetType.Single: 4>\n",
      "(Pdb) p dl\n",
      "*** NameError: name 'dl' is not defined\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(138)one_batch()\n",
      "-> dl = self.dl(ds_type)\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(139)one_batch()\n",
      "-> w = self.num_workers\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(140)one_batch()\n",
      "-> self.num_workers = 0\n",
      "(Pdb) p self.ds\n",
      "*** AttributeError: ds\n",
      "(Pdb) p self.single_ds\n",
      "LabelList\n",
      "y: CategoryList (100 items)\n",
      "[Category 1, Category 1, Category 1, Category 0, Category 0]...\n",
      "Path: /home/santhosr/Documents/Birad/ProcessedData\n",
      "x: ImageItemList (100 items)\n",
      "[Image (3, 4096, 3328), Image (3, 4096, 3328), Image (3, 3328, 2560), Image (3, 4096, 3328), Image (3, 3328, 2560)]...\n",
      "Path: /home/santhosr/Documents/Birad/ProcessedData\n",
      "(Pdb) p self.single_ds.x[0]\n",
      "Image (3, 4096, 3328)\n",
      "(Pdb) p self.single_ds.x[1]\n",
      "Image (3, 4096, 3328)\n",
      "(Pdb) p self.single_ds.x[2]\n",
      "Image (3, 3328, 2560)\n",
      "(Pdb) p self.single_dl.x[0]\n",
      "Image (3, 4096, 3328)\n",
      "(Pdb) p self.single_dl.x[1]\n",
      "Image (3, 4096, 3328)\n",
      "(Pdb) p self.single_dl.items[0]\n",
      "'/home/santhosr/Documents/Birad/ProcessedData/./FullRes/2/75048084_R_CC_1.jpg'\n",
      "(Pdb) p self.single_dl.items[1]\n",
      "'/home/santhosr/Documents/Birad/ProcessedData/./FullRes/2/76876308_R_MLO_1.jpg'\n",
      "(Pdb) ll\n",
      "136  \t    def one_batch(self, ds_type:DatasetType=DatasetType.Train, detach:bool=True, denorm:bool=True, cpu:bool=True)->Collection[Tensor]:\n",
      "137  \t        \"Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.\"\n",
      "138  \t        dl = self.dl(ds_type)\n",
      "139  \t        w = self.num_workers\n",
      "140  ->\t        self.num_workers = 0\n",
      "141  \t        try:     x,y = next(iter(dl))\n",
      "142  \t        finally: self.num_workers = w\n",
      "143  \t        if detach: x,y = to_detach(x,cpu=cpu),to_detach(y,cpu=cpu)\n",
      "144  \t        norm = getattr(self,'norm',False)\n",
      "145  \t        if denorm and norm:\n",
      "146  \t            x = self.denorm(x)\n",
      "147  \t            if norm.keywords.get('do_y',False): y = self.denorm(y, do_x=True)\n",
      "148  \t        return x,y\n",
      "(Pdb) p next(iter(dl))\n",
      "(tensor([[[[-1.8236e+00, -1.8236e+00, -1.8286e+00,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [-1.8154e+00, -1.8166e+00, -1.8191e+00,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [-1.8254e+00, -1.8304e+00, -1.8228e+00,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          ...,\n",
      "          [-1.9489e-01, -3.2107e-01, -1.0758e-01,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [-7.3464e-02, -8.2342e-02, -5.0757e-04,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [ 1.7083e-01, -1.2072e-02,  8.2581e-02,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01]],\n",
      "\n",
      "         [[-1.8236e+00, -1.8236e+00, -1.8286e+00,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [-1.8154e+00, -1.8166e+00, -1.8191e+00,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [-1.8254e+00, -1.8304e+00, -1.8228e+00,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          ...,\n",
      "          [-1.9489e-01, -3.2107e-01, -1.0758e-01,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [-7.3464e-02, -8.2342e-02, -5.0757e-04,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [ 1.7083e-01, -1.2072e-02,  8.2581e-02,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01]],\n",
      "\n",
      "         [[-1.8236e+00, -1.8236e+00, -1.8286e+00,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [-1.8154e+00, -1.8166e+00, -1.8191e+00,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [-1.8254e+00, -1.8304e+00, -1.8228e+00,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          ...,\n",
      "          [-1.9489e-01, -3.2107e-01, -1.0758e-01,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [-7.3464e-02, -8.2342e-02, -5.0757e-04,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01],\n",
      "          [ 1.7083e-01, -1.2072e-02,  8.2581e-02,  ...,  7.2550e-01,\n",
      "            7.2550e-01,  7.2550e-01]]]], device='cuda:0'), tensor([0], device='cuda:0'))\n",
      "(Pdb) p ds_type\n",
      "<DatasetType.Single: 4>\n",
      "(Pdb) ll\n",
      "136  \t    def one_batch(self, ds_type:DatasetType=DatasetType.Train, detach:bool=True, denorm:bool=True, cpu:bool=True)->Collection[Tensor]:\n",
      "137  \t        \"Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.\"\n",
      "138  \t        dl = self.dl(ds_type)\n",
      "139  \t        w = self.num_workers\n",
      "140  ->\t        self.num_workers = 0\n",
      "141  \t        try:     x,y = next(iter(dl))\n",
      "142  \t        finally: self.num_workers = w\n",
      "143  \t        if detach: x,y = to_detach(x,cpu=cpu),to_detach(y,cpu=cpu)\n",
      "144  \t        norm = getattr(self,'norm',False)\n",
      "145  \t        if denorm and norm:\n",
      "146  \t            x = self.denorm(x)\n",
      "147  \t            if norm.keywords.get('do_y',False): y = self.denorm(y, do_x=True)\n",
      "148  \t        return x,y\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(141)one_batch()\n",
      "-> try:     x,y = next(iter(dl))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(142)one_batch()\n",
      "-> finally: self.num_workers = w\n",
      "(Pdb) n\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(143)one_batch()\n",
      "-> if detach: x,y = to_detach(x,cpu=cpu),to_detach(y,cpu=cpu)\n",
      "(Pdb) p detach\n",
      "False\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(144)one_batch()\n",
      "-> norm = getattr(self,'norm',False)\n",
      "(Pdb) p norm\n",
      "*** NameError: name 'norm' is not defined\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(145)one_batch()\n",
      "-> if denorm and norm:\n",
      "(Pdb) p norm\n",
      "functools.partial(<function _normalize_batch at 0x7f4751c2cd08>, mean=tensor([0.7601, 0.7601, 0.7601]), std=tensor([0.3307, 0.3307, 0.3307]), do_x=True, do_y=False)\n",
      "(Pdb) ll\n",
      "136  \t    def one_batch(self, ds_type:DatasetType=DatasetType.Train, detach:bool=True, denorm:bool=True, cpu:bool=True)->Collection[Tensor]:\n",
      "137  \t        \"Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.\"\n",
      "138  \t        dl = self.dl(ds_type)\n",
      "139  \t        w = self.num_workers\n",
      "140  \t        self.num_workers = 0\n",
      "141  \t        try:     x,y = next(iter(dl))\n",
      "142  \t        finally: self.num_workers = w\n",
      "143  \t        if detach: x,y = to_detach(x,cpu=cpu),to_detach(y,cpu=cpu)\n",
      "144  \t        norm = getattr(self,'norm',False)\n",
      "145  ->\t        if denorm and norm:\n",
      "146  \t            x = self.denorm(x)\n",
      "147  \t            if norm.keywords.get('do_y',False): y = self.denorm(y, do_x=True)\n",
      "148  \t        return x,y\n",
      "(Pdb) p denorm\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "pdb.run('learn.predict(data.valid_dl.x[1])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
