{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil2tensor(image,dtype):\n",
    "    \"Convert PIL style `image` array to torch style image tensor.\"\n",
    "    a = np.asarray(image)\n",
    "    if a.ndim==2 : a = np.expand_dims(a,2)\n",
    "    a = np.transpose(a, (1, 0, 2))\n",
    "    a = np.transpose(a, (2, 1, 0))\n",
    "    return torch.from_numpy(a.astype(dtype, copy=False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/home/santhosr/Documents/Birad/ProcessedData/./FullRes/2/76876308_R_MLO_1.jpg'\n",
    "\n",
    "x = PIL.Image.open(filename).convert('RGB')\n",
    "\n",
    "x = pil2tensor(x,np.float32)\n",
    "\n",
    "x.div_(255)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4096, 3328])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback import *\n",
    "from fastai.basic_train import *\n",
    "import torchvision.models as tmodels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.misc import imsave\n",
    "\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import torchvision\n",
    "from torch.nn import Sigmoid\n",
    "from torch import Tensor, LongTensor\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import Sequential\n",
    "from torchvision.models.resnet import resnet50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/santhosr/Documents/Birad/FastAI/RaceClassification/' )\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from birad import *\n",
    "from birad import setTruthFile, getRaceLabel\n",
    "\n",
    "\n",
    "inputFolder1 = '/home/santhosr/Documents/Birad/ProcessedData/FullRes'\n",
    "truthFile1 = '/home/santhosr/Documents/Birad/birad_targetFile.csv'\n",
    "\n",
    "inputFolder2 = '/home/santhosr/Documents/Birad/ProcessedData/PennExtra_3500/'\n",
    "truthFile2 = '/home/santhosr/Documents/Birad/RaceDL_ExtraCaucasian.csv'\n",
    "\n",
    "df1 = pd.read_csv('/home/santhosr/Documents/Birad/birad_targetFile.csv')\n",
    "df1.drop(['PresIntentType','DBT'],inplace = True,axis=1)\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('/home/santhosr/Documents/Birad/RaceDL_ExtraCaucasian.csv')\n",
    "df2.Medview_Race = 'White'\n",
    "truth = pd.concat([df1,df2],sort=True)\n",
    "\n",
    "setTruthFile(truth)\n",
    "\n",
    "\n",
    "dfFile = \"/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/DataFile10.csv\"\n",
    "\n",
    "modelName = 'model_resnet50_id10_acc833_loss386'\n",
    "\n",
    "\n",
    "#Feature Directories\n",
    "trainFolder = '/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/Features/model9_2/train'\n",
    "\n",
    "validFolder = '/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/Features/model9_2/valid'\n",
    "\n",
    "df = pd.read_csv(dfFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([df[df.train==True].iloc[0:100], df[df.train==False].iloc[0:100], ])\n",
    "\n",
    "#Creates the FastAI Dataset\n",
    "data = ImageItemList.from_df(df=d,path='/home/santhosr/Documents/Birad/ProcessedData/', cols='filename').split_from_df(col='train').label_from_func(getRaceLabel).transform(get_transforms(),size=256).databunch(bs=50).normalize()\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-1.8236e+00, -1.8236e+00, -1.8286e+00,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [-1.8154e+00, -1.8166e+00, -1.8191e+00,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [-1.8254e+00, -1.8304e+00, -1.8228e+00,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           ...,\n",
       "           [-1.9489e-01, -3.2107e-01, -1.0758e-01,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [-7.3464e-02, -8.2342e-02, -5.0757e-04,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [ 1.7083e-01, -1.2072e-02,  8.2581e-02,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01]],\n",
       " \n",
       "          [[-1.8236e+00, -1.8236e+00, -1.8286e+00,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [-1.8154e+00, -1.8166e+00, -1.8191e+00,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [-1.8254e+00, -1.8304e+00, -1.8228e+00,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           ...,\n",
       "           [-1.9489e-01, -3.2107e-01, -1.0758e-01,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [-7.3464e-02, -8.2342e-02, -5.0757e-04,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [ 1.7083e-01, -1.2072e-02,  8.2581e-02,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01]],\n",
       " \n",
       "          [[-1.8236e+00, -1.8236e+00, -1.8286e+00,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [-1.8154e+00, -1.8166e+00, -1.8191e+00,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [-1.8254e+00, -1.8304e+00, -1.8228e+00,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           ...,\n",
       "           [-1.9489e-01, -3.2107e-01, -1.0758e-01,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [-7.3464e-02, -8.2342e-02, -5.0757e-04,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01],\n",
       "           [ 1.7083e-01, -1.2072e-02,  8.2581e-02,  ...,  7.2550e-01,\n",
       "             7.2550e-01,  7.2550e-01]]]], device='cuda:0'),\n",
       " tensor([0], device='cuda:0'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = data.one_item(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = data.single_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ds.set_item(out):\n",
    "#     batch =  data.one_batch(ds_type=DatasetType.Single, detach=False, denorm=False)\n",
    "    \n",
    "    dl = data.dl(DatasetType.Single)\n",
    "    \n",
    "    it = iter(dl)\n",
    "    \n",
    "#     x,y = next(it)\n",
    "    \n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetType = Enum('DatasetType', 'Train Valid Test Single Fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data.dl(DatasetType.Single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.7724, -1.7735, -1.7530,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.7573, -1.7706, -1.7515,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.7430, -1.7759, -1.7443,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]],\n",
       "\n",
       "         [[-1.7724, -1.7735, -1.7530,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.7573, -1.7706, -1.7515,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.7430, -1.7759, -1.7443,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]],\n",
       "\n",
       "         [[-1.7724, -1.7735, -1.7530,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.7573, -1.7706, -1.7515,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.7430, -1.7759, -1.7443,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]]],\n",
       "\n",
       "\n",
       "        [[[-1.5632, -1.5713, -1.5594,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.5333, -1.5587, -1.5765,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.5300, -1.5565, -1.5614,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]],\n",
       "\n",
       "         [[-1.5632, -1.5713, -1.5594,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.5333, -1.5587, -1.5765,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.5300, -1.5565, -1.5614,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]],\n",
       "\n",
       "         [[-1.5632, -1.5713, -1.5594,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.5333, -1.5587, -1.5765,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.5300, -1.5565, -1.5614,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]]],\n",
       "\n",
       "\n",
       "        [[[-2.0380, -2.0417, -2.0162,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-2.0157, -2.0220, -2.0142,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-2.0394, -2.0376, -2.0052,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]],\n",
       "\n",
       "         [[-2.0380, -2.0417, -2.0162,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-2.0157, -2.0220, -2.0142,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-2.0394, -2.0376, -2.0052,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]],\n",
       "\n",
       "         [[-2.0380, -2.0417, -2.0162,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-2.0157, -2.0220, -2.0142,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-2.0394, -2.0376, -2.0052,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.2839, -1.2759, -1.2768,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.2519, -1.2860, -1.2988,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.2933, -1.3438, -1.3248,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]],\n",
       "\n",
       "         [[-1.2839, -1.2759, -1.2768,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.2519, -1.2860, -1.2988,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.2933, -1.3438, -1.3248,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]],\n",
       "\n",
       "         [[-1.2839, -1.2759, -1.2768,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.2519, -1.2860, -1.2988,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [-1.2933, -1.3438, -1.3248,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]]],\n",
       "\n",
       "\n",
       "        [[[ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]],\n",
       "\n",
       "         [[ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]],\n",
       "\n",
       "         [[ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255]]],\n",
       "\n",
       "\n",
       "        [[[ 0.7255,  0.7255,  0.7255,  ..., -1.5345, -1.5476, -1.5978],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ..., -1.5400, -1.5939, -1.5697],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ..., -1.5709, -1.5855, -1.5867],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7248,  0.7119],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7245]],\n",
       "\n",
       "         [[ 0.7255,  0.7255,  0.7255,  ..., -1.5345, -1.5476, -1.5978],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ..., -1.5400, -1.5939, -1.5697],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ..., -1.5709, -1.5855, -1.5867],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7248,  0.7119],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7245]],\n",
       "\n",
       "         [[ 0.7255,  0.7255,  0.7255,  ..., -1.5345, -1.5476, -1.5978],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ..., -1.5400, -1.5939, -1.5697],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ..., -1.5709, -1.5855, -1.5867],\n",
       "          ...,\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7255],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7248,  0.7119],\n",
       "          [ 0.7255,  0.7255,  0.7255,  ...,  0.7255,  0.7255,  0.7245]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <string>(1)<module>()->None\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(68)__iter__()\n",
      "-> def __iter__(self):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.local/lib/python3.6/site-packages/fastai/basic_data.py(70)__iter__()\n",
      "-> for b in self.dl: yield self.proc_batch(b)\n",
      "(Pdb) s\n",
      "--Call--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(818)__iter__()\n",
      "-> def __iter__(self):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(819)__iter__()\n",
      "-> return _DataLoaderIter(self)\n",
      "(Pdb) n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7faa8138aeb8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(819)__iter__()-><torch.utils....x7faa80c95cf8>\n",
      "-> return _DataLoaderIter(self)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7faa8138aeb8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7faa8138aeb8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/santhosr/.conda/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) n\n",
      "--Call--\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(612)__next__()\n",
      "-> def __next__(self):\n",
      "(Pdb) s\n",
      "> /home/santhosr/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py(613)__next__()\n",
      "-> if self.num_workers == 0:  # same-process loading\n",
      "(Pdb) ll\n",
      "612  \t    def __next__(self):\n",
      "613  ->\t        if self.num_workers == 0:  # same-process loading\n",
      "614  \t            indices = next(self.sample_iter)  # may raise StopIteration\n",
      "615  \t            batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "616  \t            if self.pin_memory:\n",
      "617  \t                batch = pin_memory_batch(batch)\n",
      "618  \t            return batch\n",
      "619  \t\n",
      "620  \t        # check if the next sample has already been generated\n",
      "621  \t        if self.rcvd_idx in self.reorder_dict:\n",
      "622  \t            batch = self.reorder_dict.pop(self.rcvd_idx)\n",
      "623  \t            return self._process_next_batch(batch)\n",
      "624  \t\n",
      "625  \t        if self.batches_outstanding == 0:\n",
      "626  \t            self._shutdown_workers()\n",
      "627  \t            raise StopIteration\n",
      "628  \t\n",
      "629  \t        while True:\n",
      "630  \t            assert (not self.shutdown and self.batches_outstanding > 0)\n",
      "631  \t            idx, batch = self._get_batch()\n",
      "632  \t            self.batches_outstanding -= 1\n",
      "633  \t            if idx != self.rcvd_idx:\n",
      "634  \t                # store out-of-order samples\n",
      "635  \t                self.reorder_dict[idx] = batch\n",
      "636  \t                continue\n",
      "637  \t            return self._process_next_batch(batch)\n",
      "(Pdb) p self.dataset[0]\n",
      "(Image (3, 256, 256), Category 0)\n",
      "(Pdb) p self.collate_fn([self.dataset[0]])\n",
      "[tensor([[[[0.1740, 0.1736, 0.1804,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1790, 0.1746, 0.1809,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1837, 0.1728, 0.1833,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.1740, 0.1736, 0.1804,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1790, 0.1746, 0.1809,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1837, 0.1728, 0.1833,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.1740, 0.1736, 0.1804,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1790, 0.1746, 0.1809,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.1837, 0.1728, 0.1833,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]]), tensor([0])]\n",
      "(Pdb) p type(self)\n",
      "<class 'torch.utils.data.dataloader._DataLoaderIter'>\n",
      "(Pdb) p type(self.dataset)\n",
      "<class 'fastai.data_block.LabelList'>\n",
      "(Pdb) p self.dataset[0]\n",
      "(Image (3, 256, 256), Category 0)\n",
      "(Pdb) p type(self.dataset[0][0])\n",
      "<class 'fastai.vision.image.Image'>\n"
     ]
    }
   ],
   "source": [
    "pdb.run('x,y = next(it)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function default_collate in module torch.utils.data.dataloader:\n",
      "\n",
      "default_collate(batch)\n",
      "    Puts each data field into a tensor with outer dimension batch size\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.utils.data.dataloader.default_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def default_collate(batch):\n",
      "    r\"\"\"Puts each data field into a tensor with outer dimension batch size\"\"\"\n",
      "\n",
      "    error_msg = \"batch must contain tensors, numbers, dicts or lists; found {}\"\n",
      "    elem_type = type(batch[0])\n",
      "    if isinstance(batch[0], torch.Tensor):\n",
      "        out = None\n",
      "        if _use_shared_memory:\n",
      "            # If we're in a background process, concatenate directly into a\n",
      "            # shared memory tensor to avoid an extra copy\n",
      "            numel = sum([x.numel() for x in batch])\n",
      "            storage = batch[0].storage()._new_shared(numel)\n",
      "            out = batch[0].new(storage)\n",
      "        return torch.stack(batch, 0, out=out)\n",
      "    elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n",
      "            and elem_type.__name__ != 'string_':\n",
      "        elem = batch[0]\n",
      "        if elem_type.__name__ == 'ndarray':\n",
      "            # array of string classes and object\n",
      "            if re.search('[SaUO]', elem.dtype.str) is not None:\n",
      "                raise TypeError(error_msg.format(elem.dtype))\n",
      "\n",
      "            return torch.stack([torch.from_numpy(b) for b in batch], 0)\n",
      "        if elem.shape == ():  # scalars\n",
      "            py_type = float if elem.dtype.name.startswith('float') else int\n",
      "            return numpy_type_map[elem.dtype.name](list(map(py_type, batch)))\n",
      "    elif isinstance(batch[0], int_classes):\n",
      "        return torch.LongTensor(batch)\n",
      "    elif isinstance(batch[0], float):\n",
      "        return torch.DoubleTensor(batch)\n",
      "    elif isinstance(batch[0], string_classes):\n",
      "        return batch\n",
      "    elif isinstance(batch[0], container_abcs.Mapping):\n",
      "        return {key: default_collate([d[key] for d in batch]) for key in batch[0]}\n",
      "    elif isinstance(batch[0], container_abcs.Sequence):\n",
      "        transposed = zip(*batch)\n",
      "        return [default_collate(samples) for samples in transposed]\n",
      "\n",
      "    raise TypeError((error_msg.format(type(batch[0]))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(torch.utils.data.dataloader.default_collate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
