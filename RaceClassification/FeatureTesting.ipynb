{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback import *\n",
    "from fastai.basic_train import *\n",
    "import torchvision.models as tmodels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.misc import imsave\n",
    "\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.misc import imsave\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/santhosr/Documents/Birad/FastAI/RaceClassification/' )\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from birad import *\n",
    "from birad import setTruthFile, getRaceLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inputFolder1 = '/home/santhosr/Documents/Birad/ProcessedData/FullRes'\n",
    "truthFile1 = '/home/santhosr/Documents/Birad/birad_targetFile.csv'\n",
    "\n",
    "inputFolder2 = '/home/santhosr/Documents/Birad/ProcessedData/PennExtra_3500/'\n",
    "truthFile2 = '/home/santhosr/Documents/Birad/RaceDL_ExtraCaucasian.csv'\n",
    "\n",
    "df1 = pd.read_csv('/home/santhosr/Documents/Birad/birad_targetFile.csv')\n",
    "df1.drop(['PresIntentType','DBT'],inplace = True,axis=1)\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('/home/santhosr/Documents/Birad/RaceDL_ExtraCaucasian.csv')\n",
    "df2.Medview_Race = 'White'\n",
    "truth = pd.concat([df1,df2],sort=True)\n",
    "\n",
    "setTruthFile(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dfFile = \"DataFile9.csv\"\n",
    "\n",
    "modelName = 'model_resnet50_id9_acc848_loss376'\n",
    "\n",
    "\n",
    "#Feature Directories\n",
    "trainFolder = '/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/Features/model9_2/train'\n",
    "\n",
    "validFolder = '/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/Features/model9_2/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75218338</td>\n",
       "      <td>FullRes/3/75218338_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75145018</td>\n",
       "      <td>FullRes/2/75145018_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75913007</td>\n",
       "      <td>PennExtra_3500/75913007_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4632661</td>\n",
       "      <td>FullRes/2/4632661_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4011669</td>\n",
       "      <td>PennExtra_3500/4011669_FOR-PROCESSING_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DummyID                                           filename  train\n",
       "0  75218338                      FullRes/3/75218338_R_CC_1.jpg   True\n",
       "1  75145018                     FullRes/2/75145018_R_MLO_1.jpg   True\n",
       "2  75913007  PennExtra_3500/75913007_FOR-PROCESSING_L_CC_1.jpg  False\n",
       "3   4632661                       FullRes/2/4632661_R_CC_1.jpg   True\n",
       "4   4011669   PennExtra_3500/4011669_FOR-PROCESSING_R_CC_1.jpg  False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dfFile)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "#Creates the FastAI Dataset\n",
    "data = ImageItemList.from_df(df=df,path='/home/santhosr/Documents/Birad/ProcessedData/', cols='filename').split_from_df(col='train').label_from_func(getRaceLabel).transform(get_transforms(),size=256).databunch(bs=50).normalize()\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: CategoryList (32000 items)\n",
       "[Category 1, Category 1, Category 1, Category 1, Category 0]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData\n",
       "x: ImageItemList (32000 items)\n",
       "[Image (3, 4096, 3328), Image (3, 3328, 2560), Image (3, 4096, 3328), Image (3, 4096, 3328), Image (3, 4096, 3328)]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData;\n",
       "\n",
       "Valid: LabelList\n",
       "y: CategoryList (8000 items)\n",
       "[Category 1, Category 1, Category 0, Category 0, Category 0]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData\n",
       "x: ImageItemList (8000 items)\n",
       "[Image (3, 3328, 2560), Image (3, 3328, 2560), Image (3, 4096, 3328), Image (3, 4096, 3328), Image (3, 4096, 3328)]...\n",
       "Path: /home/santhosr/Documents/Birad/ProcessedData;\n",
       "\n",
       "Test: None, model=Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Lambda()\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f8287d1df98>, metrics=[<function accuracy at 0x7f8224a5bd90>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/santhosr/Documents/Birad/ProcessedData'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU(inplace)\n",
       "  (11): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace)\n",
       "  (20): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (24): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU(inplace)\n",
       "  (27): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (30): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (31): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (33): ReLU(inplace)\n",
       "  (34): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (38): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (40): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (42): ReLU(inplace)\n",
       "  (43): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (44): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (45): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (46): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (47): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (49): ReLU(inplace)\n",
       "  (50): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (51): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (52): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (54): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (56): ReLU(inplace)\n",
       "), Sequential(\n",
       "  (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (14): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): ReLU(inplace)\n",
       "  (16): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): ReLU(inplace)\n",
       "  (23): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (27): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): ReLU(inplace)\n",
       "  (30): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (34): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (35): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): ReLU(inplace)\n",
       "  (37): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (39): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (40): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (41): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (42): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (43): ReLU(inplace)\n",
       "  (44): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (48): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (50): ReLU(inplace)\n",
       "  (51): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (52): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (53): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (55): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (56): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (57): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (58): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (59): ReLU(inplace)\n",
       "  (60): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (62): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (64): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (66): ReLU(inplace)\n",
       "), Sequential(\n",
       "  (0): AdaptiveAvgPool2d(output_size=1)\n",
       "  (1): AdaptiveMaxPool2d(output_size=1)\n",
       "  (2): Lambda()\n",
       "  (3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Dropout(p=0.25)\n",
       "  (5): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Dropout(p=0.5)\n",
       "  (9): Linear(in_features=512, out_features=2, bias=True)\n",
       ")])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates the model architecture \n",
    "learn = create_cnn(data, tmodels.resnet50, metrics=accuracy,pretrained=True)\n",
    "\n",
    "learn.load('/home/santhosr/Documents/Birad/ProcessedData/models/'+modelName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "layer = list(learn.model.children())[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): Lambda()\n",
       "  (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.25)\n",
       "  (4): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (5): ReLU(inplace)\n",
       "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.5)\n",
       "  (8): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(learn.model.children())[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "learn.model.eval()\n",
    "\n",
    "#Setting the layer from which we are extracting features\n",
    "layer = list(learn.model.children())[1][4]\n",
    "\n",
    "my_embedding = 0\n",
    "\n",
    "def copyData(m, inp, out):\n",
    "    global my_embedding\n",
    "    out1 = out.detach().cpu().numpy()\n",
    "    my_embedding = out1\n",
    "\n",
    "#Registering a forward hook\n",
    "feat = layer.register_forward_hook(copyData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Extracting Features (Train Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 114/28160 [00:29<1:42:21,  4.57it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-26607f4ab3a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_item\u001b[0;34m(self, item, detach, denorm)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdenorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, ds_type, detach, denorm, cpu)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/data_block.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idxs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m   \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfmargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tfms_y'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfm_y\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfmargs_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'do_resolve'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mapply_tfms\u001b[0;34m(self, tfms, do_resolve, xtra, size, resize_method, mult, padding_mode, mode)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mtfms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_resolve\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_resolve_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;34m\"Mimic the behavior of torch.clone for `Image` objects.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Train Data\n",
    "\n",
    "for i in tqdm(range(len(data.train_ds.items))):\n",
    "    \n",
    "    e=data.one_item(data.train_ds.x[i])\n",
    "    pred = learn.model(e[0])\n",
    "    \n",
    "    file = data.train_ds.items[i].split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    np.save( os.path.join(trainFolder, file+'.npy'), my_embedding )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Extracting Features (Valid Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 141/8000 [00:34<30:00,  4.37it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-62bede4da7ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/data_block.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idxs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/data.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/data.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;34m\"Open image in `fn`, subclass and overwrite for custom behavior.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mopen_image\u001b[0;34m(fn, div, convert_mode, cls)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# EXIF warning from TiffPlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mpil2tensor\u001b[0;34m(image, dtype)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimage2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Valid Data\n",
    "\n",
    "for i in tqdm(range(len(data.valid_ds.items))):\n",
    "    \n",
    "    e=data.one_item(data.valid_ds.x[i])\n",
    "    pred = learn.model(e[0])\n",
    "    \n",
    "    file = data.valid_ds.items[i].split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    np.save( os.path.join(validFolder, file+'.npy'), my_embedding )\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/8000 [00:00<28:17,  4.71it/s]\u001b[A\n",
      "  0%|          | 2/8000 [00:00<28:02,  4.75it/s]\u001b[A\n",
      "  0%|          | 3/8000 [00:00<31:24,  4.24it/s]\u001b[A\n",
      "  0%|          | 4/8000 [00:00<32:58,  4.04it/s]\u001b[A\n",
      "  0%|          | 5/8000 [00:01<33:59,  3.92it/s]\u001b[A\n",
      "  0%|          | 6/8000 [00:01<30:57,  4.30it/s]\u001b[A\n",
      "  0%|          | 7/8000 [00:01<29:22,  4.54it/s]\u001b[A\n",
      "  0%|          | 8/8000 [00:01<32:10,  4.14it/s]\u001b[A\n",
      "  0%|          | 9/8000 [00:02<33:55,  3.93it/s]\u001b[A\n",
      "  0%|          | 10/8000 [00:02<30:55,  4.31it/s]\u001b[A\n",
      "  0%|          | 11/8000 [00:02<29:12,  4.56it/s]\u001b[A\n",
      "  0%|          | 12/8000 [00:02<32:11,  4.14it/s]\u001b[A\n",
      "  0%|          | 13/8000 [00:03<33:19,  3.99it/s]\u001b[A\n",
      "  0%|          | 14/8000 [00:03<34:38,  3.84it/s]\u001b[A\n",
      "  0%|          | 15/8000 [00:03<31:24,  4.24it/s]\u001b[A\n",
      "  0%|          | 16/8000 [00:03<29:34,  4.50it/s]\u001b[A\n",
      "  0%|          | 17/8000 [00:03<28:13,  4.71it/s]\u001b[A\n",
      "  0%|          | 18/8000 [00:04<31:24,  4.24it/s]\u001b[A\n",
      "  0%|          | 19/8000 [00:04<28:59,  4.59it/s]\u001b[A\n",
      "  0%|          | 20/8000 [00:04<27:53,  4.77it/s]\u001b[A\n",
      "  0%|          | 21/8000 [00:04<27:05,  4.91it/s]\u001b[A\n",
      "  0%|          | 22/8000 [00:05<26:46,  4.97it/s]\u001b[A\n",
      "  0%|          | 23/8000 [00:05<26:31,  5.01it/s]\u001b[A\n",
      "  0%|          | 24/8000 [00:05<30:15,  4.39it/s]\u001b[A\n",
      "  0%|          | 25/8000 [00:05<28:17,  4.70it/s]\u001b[A\n",
      "  0%|          | 26/8000 [00:05<31:16,  4.25it/s]\u001b[A\n",
      "  0%|          | 27/8000 [00:06<29:03,  4.57it/s]\u001b[A\n",
      "  0%|          | 28/8000 [00:06<32:09,  4.13it/s]\u001b[A\n",
      "  0%|          | 29/8000 [00:06<33:29,  3.97it/s]\u001b[A\n",
      "  0%|          | 30/8000 [00:07<34:37,  3.84it/s]\u001b[A\n",
      "  0%|          | 31/8000 [00:07<31:24,  4.23it/s]\u001b[A\n",
      "  0%|          | 32/8000 [00:07<34:18,  3.87it/s]\u001b[A\n",
      "  0%|          | 33/8000 [00:07<35:08,  3.78it/s]\u001b[A\n",
      "  0%|          | 34/8000 [00:08<36:01,  3.69it/s]\u001b[A\n",
      "  0%|          | 35/8000 [00:08<36:25,  3.65it/s]\u001b[A\n",
      "  0%|          | 36/8000 [00:08<37:00,  3.59it/s]\u001b[A\n",
      "  0%|          | 37/8000 [00:08<33:13,  3.99it/s]\u001b[A\n",
      "  0%|          | 38/8000 [00:09<35:09,  3.77it/s]\u001b[A\n",
      "  0%|          | 39/8000 [00:09<35:59,  3.69it/s]\u001b[A\n",
      "  0%|          | 40/8000 [00:09<36:27,  3.64it/s]\u001b[A\n",
      "  1%|          | 41/8000 [00:09<36:56,  3.59it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-93c90f7154c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerateFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-a424eeee8c13>\u001b[0m in \u001b[0;36mgenerateFeatures\u001b[0;34m(learn, dataset, trainFolder, validFolder)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_item\u001b[0;34m(self, item, detach, denorm)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdenorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, ds_type, detach, denorm, cpu)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/data_block.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idxs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m   \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfmargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tfms_y'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfm_y\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfmargs_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'do_resolve'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mapply_tfms\u001b[0;34m(self, tfms, do_resolve, xtra, size, resize_method, mult, padding_mode, mode)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mtfms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_resolve\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_resolve_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;34m\"Mimic the behavior of torch.clone for `Image` objects.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generateFeatures(learn, data, trainFolder, validFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": true
   },
   "source": [
    "### Combined Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "train = df[df.train == False]\n",
    "test = df[df.train == True]\n",
    "\n",
    "trainy = train.label.copy()\n",
    "testy = test.label.copy()\n",
    "\n",
    "# keepList = ['VolumetricBreastDensity','DenseAreaPercent','Age','BMI']\n",
    "# # keepList = ['DenseAreaPercent','Age','BMI']\n",
    "\n",
    "# trainx = train[keepList]\n",
    "# testx = test[keepList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75426529</td>\n",
       "      <td>PennExtra_3500/75426529_FOR-PROCESSING_R_MLO_1...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75682563</td>\n",
       "      <td>FullRes/3/75682563_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75761285</td>\n",
       "      <td>PennExtra_3500/75761285_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4261353</td>\n",
       "      <td>FullRes/2/4261353_L_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75456219</td>\n",
       "      <td>FullRes/2/75456219_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DummyID                                           filename  train\n",
       "0  75426529  PennExtra_3500/75426529_FOR-PROCESSING_R_MLO_1...  False\n",
       "1  75682563                     FullRes/3/75682563_R_MLO_1.jpg  False\n",
       "2  75761285  PennExtra_3500/75761285_FOR-PROCESSING_L_CC_1.jpg  False\n",
       "3   4261353                      FullRes/2/4261353_L_MLO_1.jpg  False\n",
       "4  75456219                     FullRes/2/75456219_R_MLO_1.jpg   True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Density_Overall</th>\n",
       "      <th>DummyID</th>\n",
       "      <th>Medview_Race</th>\n",
       "      <th>ScreenDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.8</td>\n",
       "      <td>27.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2508626</td>\n",
       "      <td>White</td>\n",
       "      <td>3/23/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.8</td>\n",
       "      <td>25.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2505738</td>\n",
       "      <td>White</td>\n",
       "      <td>6/2/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.4</td>\n",
       "      <td>28.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2547962</td>\n",
       "      <td>White</td>\n",
       "      <td>5/24/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.7</td>\n",
       "      <td>31.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2575490</td>\n",
       "      <td>White</td>\n",
       "      <td>5/6/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.7</td>\n",
       "      <td>27.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2591080</td>\n",
       "      <td>Other</td>\n",
       "      <td>5/5/2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age   BMI  Density_Overall  DummyID Medview_Race ScreenDate\n",
       "0  67.8  27.1              2.0  2508626        White  3/23/2011\n",
       "1  58.8  25.7              2.0  2505738        White   6/2/2011\n",
       "2  56.4  28.1              2.0  2547962        White  5/24/2011\n",
       "3  51.7  31.8              2.0  2575490        White   5/6/2011\n",
       "4  63.7  27.5              2.0  2591080        Other   5/5/2011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['label'] = df.filename.apply(lambda x : getRaceLabel(x))\n",
    "\n",
    "df['DummyID'] = df.filename.apply(lambda x : int(x.split(\"/\")[-1].split(\"_\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extractImageName(x):\n",
    "    \n",
    "    x = x.split(\"/\")[-1]\n",
    "    \n",
    "    if \"MLO\" in x :\n",
    "        return x[-11:-6]\n",
    "    else:\n",
    "        return x[-10:-6]\n",
    "    \n",
    "df['ImageName'] = df.filename.apply(lambda x : x.split(\"/\")[-1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Density_Overall</th>\n",
       "      <th>DummyID</th>\n",
       "      <th>Medview_Race</th>\n",
       "      <th>ScreenDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.8</td>\n",
       "      <td>27.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2508626</td>\n",
       "      <td>White</td>\n",
       "      <td>3/23/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.8</td>\n",
       "      <td>25.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2505738</td>\n",
       "      <td>White</td>\n",
       "      <td>6/2/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.4</td>\n",
       "      <td>28.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2547962</td>\n",
       "      <td>White</td>\n",
       "      <td>5/24/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.7</td>\n",
       "      <td>31.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2575490</td>\n",
       "      <td>White</td>\n",
       "      <td>5/6/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.7</td>\n",
       "      <td>27.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2591080</td>\n",
       "      <td>Other</td>\n",
       "      <td>5/5/2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age   BMI  Density_Overall  DummyID Medview_Race ScreenDate\n",
       "0  67.8  27.1              2.0  2508626        White  3/23/2011\n",
       "1  58.8  25.7              2.0  2505738        White   6/2/2011\n",
       "2  56.4  28.1              2.0  2547962        White  5/24/2011\n",
       "3  51.7  31.8              2.0  2575490        White   5/6/2011\n",
       "4  63.7  27.5              2.0  2591080        Other   5/5/2011"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, truth[['DummyID','Age','BMI']], on='DummyID', how='left')\n",
    "\n",
    "#Removing instances without BMI\n",
    "df = df.loc[~pd.isna(df.BMI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16928\n",
       "0    16636\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": true
   },
   "source": [
    "### Patient Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "      <th>label</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75426529</td>\n",
       "      <td>PennExtra_3500/75426529_FOR-PROCESSING_R_MLO_1...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>75426529_FOR-PROCESSING_R_MLO_1</td>\n",
       "      <td>69.3</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75682563</td>\n",
       "      <td>FullRes/3/75682563_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>75682563_R_MLO_1</td>\n",
       "      <td>52.4</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75761285</td>\n",
       "      <td>PennExtra_3500/75761285_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>75761285_FOR-PROCESSING_L_CC_1</td>\n",
       "      <td>66.4</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4261353</td>\n",
       "      <td>FullRes/2/4261353_L_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4261353_L_MLO_1</td>\n",
       "      <td>66.8</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75456219</td>\n",
       "      <td>FullRes/2/75456219_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>75456219_R_MLO_1</td>\n",
       "      <td>74.5</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DummyID                                           filename  train  label  \\\n",
       "0  75426529  PennExtra_3500/75426529_FOR-PROCESSING_R_MLO_1...  False      1   \n",
       "1  75682563                     FullRes/3/75682563_R_MLO_1.jpg  False      0   \n",
       "2  75761285  PennExtra_3500/75761285_FOR-PROCESSING_L_CC_1.jpg  False      1   \n",
       "3   4261353                      FullRes/2/4261353_L_MLO_1.jpg  False      0   \n",
       "4  75456219                     FullRes/2/75456219_R_MLO_1.jpg   True      0   \n",
       "\n",
       "                         ImageName   Age   BMI  \n",
       "0  75426529_FOR-PROCESSING_R_MLO_1  69.3  28.7  \n",
       "1                 75682563_R_MLO_1  52.4  32.7  \n",
       "2   75761285_FOR-PROCESSING_L_CC_1  66.4  26.3  \n",
       "3                  4261353_L_MLO_1  66.8  32.4  \n",
       "4                 75456219_R_MLO_1  74.5  24.1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trainPatients = pd.unique(df.loc[df.train==False]['DummyID'])\n",
    "validPatients = pd.unique(df.loc[df.train==True]['DummyID'])\n",
    "\n",
    "dropList = []\n",
    "for i in range(len(trainPatients)):\n",
    "    d = df[df.DummyID == trainPatients[i]]\n",
    "    if len(d)!=4:\n",
    "        dropList.append(trainPatients[i])\n",
    "\n",
    "trainPatients = list(set(trainPatients).difference(set(dropList)))\n",
    "\n",
    "\n",
    "dropList = []\n",
    "for i in range(len(validPatients)):\n",
    "    d = df[df.DummyID == validPatients[i]]\n",
    "    if len(d)!=4:\n",
    "        dropList.append(validPatients[i])\n",
    "\n",
    "validPatients = list(set(validPatients).difference(set(dropList)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6693"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainPatients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1652"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validPatients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "#### With Patient Data Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Train data\n",
    "trainData = []\n",
    "trainLabel = []\n",
    "for i in range(len(trainPatients)):\n",
    "    \n",
    "    r = df[df.DummyID==trainPatients[i]]\n",
    "#     val = list(r['VolumetricBreastDensity'].values) + list(r['DenseAreaPercent'].values) + \\\n",
    "#             [r.iloc[0]['Age']] + [r.iloc[0]['BMI']]\n",
    "    val =  [r.iloc[0]['Age']] + [r.iloc[0]['BMI']]\n",
    "        \n",
    "    trainData.append(val)\n",
    "    trainLabel.append(r.iloc[0]['label'])\n",
    "    \n",
    "trainData = np.array(trainData)\n",
    "trainLabel = np.array(trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Valid data\n",
    "validData = []\n",
    "validLabel = []\n",
    "for i in range(len(validPatients)):\n",
    "    \n",
    "    r = df[df.DummyID==validPatients[i]]\n",
    "    val =  [r.iloc[0]['Age']] + [r.iloc[0]['BMI']]\n",
    "        \n",
    "    validData.append(val)\n",
    "    validLabel.append(r.iloc[0]['label'])\n",
    "    \n",
    "validData = np.array(validData)\n",
    "validLabel = np.array(validLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "      <th>label</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75426529</td>\n",
       "      <td>PennExtra_3500/75426529_FOR-PROCESSING_R_MLO_1...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>R_MLO</td>\n",
       "      <td>69.3</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75682563</td>\n",
       "      <td>FullRes/3/75682563_R_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>R_MLO</td>\n",
       "      <td>52.4</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75761285</td>\n",
       "      <td>PennExtra_3500/75761285_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>L_CC</td>\n",
       "      <td>66.4</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4261353</td>\n",
       "      <td>FullRes/2/4261353_L_MLO_1.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>L_MLO</td>\n",
       "      <td>66.8</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75456219</td>\n",
       "      <td>FullRes/2/75456219_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>R_MLO</td>\n",
       "      <td>74.5</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DummyID                                           filename  train  label  \\\n",
       "0  75426529  PennExtra_3500/75426529_FOR-PROCESSING_R_MLO_1...  False      1   \n",
       "1  75682563                     FullRes/3/75682563_R_MLO_1.jpg  False      0   \n",
       "2  75761285  PennExtra_3500/75761285_FOR-PROCESSING_L_CC_1.jpg  False      1   \n",
       "3   4261353                      FullRes/2/4261353_L_MLO_1.jpg  False      0   \n",
       "4  75456219                     FullRes/2/75456219_R_MLO_1.jpg   True      0   \n",
       "\n",
       "  ImageName   Age   BMI  \n",
       "0     R_MLO  69.3  28.7  \n",
       "1     R_MLO  52.4  32.7  \n",
       "2      L_CC  66.4  26.3  \n",
       "3     L_MLO  66.8  32.4  \n",
       "4     R_MLO  74.5  24.1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "source": [
    "#### With Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Train data\n",
    "trainData = []\n",
    "trainLabel = []\n",
    "for i in range(len(trainPatients)):\n",
    "    \n",
    "    r = df[df.DummyID==trainPatients[i]]\n",
    "    r = r.sort_values('ImageName')\n",
    "    \n",
    "    val =  [r.iloc[0]['Age']] + [r.iloc[0]['BMI']]\n",
    "    \n",
    "    imageData = []\n",
    "    for i in range(4):\n",
    "        feat  = list(np.load(os.path.join(trainFolder,r.iloc[i]['ImageName']+'.npy')).reshape(-1))\n",
    "        imageData = imageData + feat\n",
    "    \n",
    "    trainData.append(val+imageData)   #add val here for confounding vars\n",
    "    trainLabel.append(r.iloc[0]['label'])\n",
    "    \n",
    "trainData = np.array(trainData)\n",
    "trainLabel = np.array(trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### valid data\n",
    "validData = []\n",
    "validLabel = []\n",
    "for i in range(len(validPatients)):\n",
    "    \n",
    "    r = df[df.DummyID==validPatients[i]]\n",
    "    r = r.sort_values('ImageName')\n",
    "    \n",
    "    val =       [r.iloc[0]['Age']] + [r.iloc[0]['BMI']]\n",
    "    \n",
    "    imageData = []\n",
    "    for i in range(4):\n",
    "        feat  = list(np.load(os.path.join(validFolder,r.iloc[i]['ImageName']+'.npy')).reshape(-1))\n",
    "        imageData = imageData + feat\n",
    "    \n",
    "    validData.append(val +imageData )\n",
    "    validLabel.append(r.iloc[0]['label'])\n",
    "    \n",
    "validData = np.array(validData)\n",
    "validLabel = np.array(validLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MODELING\n",
    "\n",
    "\n",
    "rfModel = RandomForestClassifier(n_estimators=300, max_depth=12)\n",
    "rfModel.fit(trainData, trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8886198547215496"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rfModel.predict(validData)\n",
    "accuracy_score(pred, validLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8886315666041276"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(validLabel,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "Collapsed": "false",
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [06:07<00:00, 36.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8878928206000325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CV Testing\n",
    "\n",
    "scoreList = []\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    rfModel = RandomForestClassifier(n_estimators=300, max_depth=10)\n",
    "    rfModel.fit(trainData, trainLabel)\n",
    "    \n",
    "    pred = rfModel.predict(validData)\n",
    "    score = roc_auc_score(pred, validLabel)\n",
    "    \n",
    "    scoreList.append(score)\n",
    "    \n",
    "print(np.mean(scoreList))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Keras Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "inputShape = (2050,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(1024, activation='relu',input_shape=inputShape))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6693 samples, validate on 1652 samples\n",
      "Epoch 1/10\n",
      "6693/6693 [==============================] - 1s 207us/step - loss: 0.4066 - acc: 0.8921 - val_loss: 0.3446 - val_acc: 0.8801\n",
      "Epoch 2/10\n",
      "6693/6693 [==============================] - 1s 123us/step - loss: 0.2402 - acc: 0.9228 - val_loss: 0.3307 - val_acc: 0.8886\n",
      "Epoch 3/10\n",
      "6693/6693 [==============================] - 1s 124us/step - loss: 0.2030 - acc: 0.9355 - val_loss: 0.3084 - val_acc: 0.8898\n",
      "Epoch 4/10\n",
      "6693/6693 [==============================] - 1s 124us/step - loss: 0.1839 - acc: 0.9381 - val_loss: 0.3700 - val_acc: 0.8874\n",
      "Epoch 5/10\n",
      "6693/6693 [==============================] - 1s 123us/step - loss: 0.1763 - acc: 0.9398 - val_loss: 0.3109 - val_acc: 0.8959\n",
      "Epoch 6/10\n",
      "6693/6693 [==============================] - 1s 125us/step - loss: 0.1653 - acc: 0.9474 - val_loss: 0.3416 - val_acc: 0.8941\n",
      "Epoch 7/10\n",
      "6693/6693 [==============================] - 1s 125us/step - loss: 0.1504 - acc: 0.9501 - val_loss: 0.3879 - val_acc: 0.8953\n",
      "Epoch 8/10\n",
      "6693/6693 [==============================] - 1s 125us/step - loss: 0.1453 - acc: 0.9553 - val_loss: 0.3897 - val_acc: 0.8959\n",
      "Epoch 9/10\n",
      "6693/6693 [==============================] - 1s 123us/step - loss: 0.1366 - acc: 0.9571 - val_loss: 0.3897 - val_acc: 0.8929\n",
      "Epoch 10/10\n",
      "6693/6693 [==============================] - 1s 125us/step - loss: 0.1272 - acc: 0.9598 - val_loss: 0.4291 - val_acc: 0.8935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4841e1278>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainData, trainLabel,\n",
    "          batch_size=50,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(validData, validLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(1024, activation='relu',input_shape=inputShape))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6693 samples, validate on 1652 samples\n",
      "Epoch 1/10\n",
      "6693/6693 [==============================] - 1s 181us/step - loss: 0.3685 - acc: 0.9000 - val_loss: 0.3670 - val_acc: 0.8729\n",
      "Epoch 2/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.2278 - acc: 0.9269 - val_loss: 0.3679 - val_acc: 0.8820\n",
      "Epoch 3/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.2192 - acc: 0.9311 - val_loss: 0.3391 - val_acc: 0.8826\n",
      "Epoch 4/10\n",
      "6693/6693 [==============================] - 1s 112us/step - loss: 0.2052 - acc: 0.9362 - val_loss: 0.3450 - val_acc: 0.8874\n",
      "Epoch 5/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.1953 - acc: 0.9353 - val_loss: 0.3355 - val_acc: 0.8856\n",
      "Epoch 6/10\n",
      "6693/6693 [==============================] - 1s 109us/step - loss: 0.1718 - acc: 0.9432 - val_loss: 0.3712 - val_acc: 0.8935\n",
      "Epoch 7/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.1718 - acc: 0.9450 - val_loss: 0.4069 - val_acc: 0.8929\n",
      "Epoch 8/10\n",
      "6693/6693 [==============================] - 1s 111us/step - loss: 0.1733 - acc: 0.9471 - val_loss: 0.4052 - val_acc: 0.8904\n",
      "Epoch 9/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.1652 - acc: 0.9482 - val_loss: 0.4185 - val_acc: 0.8874\n",
      "Epoch 10/10\n",
      "6693/6693 [==============================] - 1s 110us/step - loss: 0.1654 - acc: 0.9504 - val_loss: 0.4520 - val_acc: 0.8850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc56ebd0518>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainData, trainLabel,\n",
    "          batch_size=50,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(validData, validLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Making predictions for single images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "\n",
    "img = imread('/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/75218338_R_CC_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyID</th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75218338</td>\n",
       "      <td>FullRes/3/75218338_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75145018</td>\n",
       "      <td>FullRes/2/75145018_R_MLO_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75913007</td>\n",
       "      <td>PennExtra_3500/75913007_FOR-PROCESSING_L_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4632661</td>\n",
       "      <td>FullRes/2/4632661_R_CC_1.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4011669</td>\n",
       "      <td>PennExtra_3500/4011669_FOR-PROCESSING_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DummyID                                           filename  train\n",
       "0  75218338                      FullRes/3/75218338_R_CC_1.jpg   True\n",
       "1  75145018                     FullRes/2/75145018_R_MLO_1.jpg   True\n",
       "2  75913007  PennExtra_3500/75913007_FOR-PROCESSING_L_CC_1.jpg  False\n",
       "3   4632661                       FullRes/2/4632661_R_CC_1.jpg   True\n",
       "4   4011669   PennExtra_3500/4011669_FOR-PROCESSING_R_CC_1.jpg  False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>withLargerDataset/75218338_R_CC_1.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>withLargerDataset/75218338_R_CC_11.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>withLargerDataset/75218338_R_CC_12.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>withLargerDataset/75218338_R_CC_13.jpg</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>withLargerDataset/75218338_R_CC_14.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename  train\n",
       "0   withLargerDataset/75218338_R_CC_1.jpg  False\n",
       "1  withLargerDataset/75218338_R_CC_11.jpg  False\n",
       "2  withLargerDataset/75218338_R_CC_12.jpg   True\n",
       "3  withLargerDataset/75218338_R_CC_13.jpg  False\n",
       "4  withLargerDataset/75218338_R_CC_14.jpg   True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame([['withLargerDataset/75218338_R_CC_1.jpg',False],['withLargerDataset/75218338_R_CC_11.jpg',False],['withLargerDataset/75218338_R_CC_12.jpg',True],['withLargerDataset/75218338_R_CC_13.jpg',False],['withLargerDataset/75218338_R_CC_14.jpg',True]])\n",
    "df1.columns = ['filename','train']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function _normalize_batch at 0x7f82240b1950>, mean=tensor([0.7549, 0.7549, 0.7549]), std=tensor([0.3382, 0.3382, 0.3382]), do_x=True, do_y=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/santhosr/Documents/Birad/ProcessedData/./FullRes/3/75218338_R_CC_1.jpg'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.valid_ds.items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotImageData('75218338_R_CC_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "p=learn.predict(data.valid_ds.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0074, 0.9926]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0954,  2.8065]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.7549, 0.7549, 0.7549]), tensor([0.3382, 0.3382, 0.3382])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize\n",
    "\n",
    "tfms = torchvision.transforms.Compose([\n",
    "    Resize([256,256]),\n",
    "    ToTensor(),\n",
    "    Normalize(data.stats[0],data.stats[1])\n",
    "    \n",
    "    \n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "img = PIL.Image.open('/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/75218338_R_CC_1.jpg').convert('RGB')\n",
    "\n",
    "p = tfms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Creates the FastAI Dataset\n",
    "data = ImageItemList.from_df(df=df,path='/home/santhosr/Documents/Birad/ProcessedData/', cols='filename').split_from_df(col='train').label_from_func(getRaceLabel).transform(get_transforms(),size=256).databunch(bs=50).normalize()\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "q=data.valid_ds.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "e=data.one_item(data.valid_ds.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0,1:10,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247],\n",
       "        [0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247, 0.7247]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0][0,0,1:10,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6960,  2.6999]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(p.unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6956,  2.6995]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(p.unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0954,  2.8065]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(e[0].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          ...,\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]],\n",
       "\n",
       "         [[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          ...,\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]],\n",
       "\n",
       "         [[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          ...,\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "          [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         ...,\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]],\n",
       "\n",
       "        [[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         ...,\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]],\n",
       "\n",
       "        [[0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         ...,\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247],\n",
       "         [0.7247, 0.7247, 0.7247,  ..., 0.7247, 0.7247, 0.7247]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f81d40cefd0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.transpose(p.numpy(),[1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72472656"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(p.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1049395"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(p.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72472656"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(e[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.131105"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(e[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-fdd2b0be2489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/75218338_R_CC_1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from fastai.vision import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    400\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_px\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.__class__.__name__} {tuple(self.shape)}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_px\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.__class__.__name__} {tuple(self.shape)}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m_repr_image_format\u001b[0;34m(self, format_str)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstr_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstr_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mimage2np\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimage2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m\"Convert from torch style `image` to numpy/matplotlib style.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'cpu'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m_repr_jpeg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.__class__.__name__} {tuple(self.shape)}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36m_repr_image_format\u001b[0;34m(self, format_str)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstr_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstr_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/vision/image.py\u001b[0m in \u001b[0;36mimage2np\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimage2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m\"Convert from torch style `image` to numpy/matplotlib style.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "Image('/home/santhosr/Documents/Birad/FastAI/RaceClassification/withLargerDataset/75218338_R_CC_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Image in module fastai.vision.image:\n",
      "\n",
      "class Image(fastai.core.ItemBase)\n",
      " |  Support applying transforms to image data in `px`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Image\n",
      " |      fastai.core.ItemBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, px:torch.Tensor)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  affine(self, func:Callable[[Dict[str, Any]], torch.Tensor], *args, **kwargs) -> 'Image'\n",
      " |      Equivalent to `image.affine_mat = image.affine_mat @ func()`.\n",
      " |  \n",
      " |  apply_tfms(self, tfms:Union[Callable, Collection[Callable]], do_resolve:bool=True, xtra:Union[Dict[Callable, dict], NoneType]=None, size:Union[int, Tuple[int, int, int], NoneType]=None, resize_method:fastai.vision.image.ResizeMethod=<ResizeMethod.CROP: 1>, mult:int=32, padding_mode:str='reflection', mode:str='bilinear') -> torch.Tensor\n",
      " |      Apply all `tfms` to the `Image`, if `do_resolve` picks value for random args.\n",
      " |  \n",
      " |  brightness lambda x, *args, **kwargs\n",
      " |  \n",
      " |  clone(self)\n",
      " |      Mimic the behavior of torch.clone for `Image` objects.\n",
      " |  \n",
      " |  contrast lambda x, *args, **kwargs\n",
      " |  \n",
      " |  coord(self, func:Callable[[fastai.vision.image.FlowField, Collection[Any], Dict[str, Any]], torch.Tensor], *args, **kwargs) -> 'Image'\n",
      " |      Equivalent to `image.flow = func(image.flow, image.size)`.\n",
      " |  \n",
      " |  crop lambda x, *args, **kwargs\n",
      " |  \n",
      " |  crop_pad lambda x, *args, **kwargs\n",
      " |  \n",
      " |  dihedral lambda x, *args, **kwargs\n",
      " |  \n",
      " |  dihedral_affine lambda x, *args, **kwargs\n",
      " |  \n",
      " |  flip_affine lambda x, *args, **kwargs\n",
      " |  \n",
      " |  flip_lr lambda x, *args, **kwargs\n",
      " |  \n",
      " |  jitter lambda x, *args, **kwargs\n",
      " |  \n",
      " |  lighting(self, func:Callable[[torch.Tensor, Collection[Any], Dict[str, Any]], torch.Tensor], *args:Any, **kwargs:Any)\n",
      " |      Equivalent to `image = sigmoid(func(logit(image)))`.\n",
      " |  \n",
      " |  pad lambda x, *args, **kwargs\n",
      " |  \n",
      " |  perspective_warp lambda x, *args, **kwargs\n",
      " |  \n",
      " |  pixel(self, func:Callable[[torch.Tensor, Collection[Any], Dict[str, Any]], torch.Tensor], *args, **kwargs) -> 'Image'\n",
      " |      Equivalent to `image.px = func(image.px)`.\n",
      " |  \n",
      " |  refresh(self) -> None\n",
      " |      Apply any logit, flow, or affine transfers that have been sent to the `Image`.\n",
      " |  \n",
      " |  resize(self, size:Union[int, Tuple[int, int, int]]) -> 'Image'\n",
      " |      Resize the image to `size`, size can be a single int.\n",
      " |  \n",
      " |  rotate lambda x, *args, **kwargs\n",
      " |  \n",
      " |  save(self, fn:Union[pathlib.Path, str])\n",
      " |      Save the image to `fn`.\n",
      " |  \n",
      " |  set_sample(self, **kwargs) -> 'ImageBase'\n",
      " |      Set parameters that control how we `grid_sample` the image after transforms are applied.\n",
      " |  \n",
      " |  show(self, ax:matplotlib.axes._axes.Axes=None, figsize:tuple=(3, 3), title:Union[str, NoneType]=None, hide_axis:bool=True, cmap:str=None, y:Any=None, **kwargs)\n",
      " |      Show image on `ax` with `title`, using `cmap` if single-channel, overlaid with optional `y`\n",
      " |  \n",
      " |  skew lambda x, *args, **kwargs\n",
      " |  \n",
      " |  squish lambda x, *args, **kwargs\n",
      " |  \n",
      " |  symmetric_warp lambda x, *args, **kwargs\n",
      " |  \n",
      " |  tilt lambda x, *args, **kwargs\n",
      " |  \n",
      " |  zoom lambda x, *args, **kwargs\n",
      " |  \n",
      " |  zoom_squish lambda x, *args, **kwargs\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  affine_mat\n",
      " |      Get the affine matrix that will be applied by `refresh`.\n",
      " |  \n",
      " |  data\n",
      " |      Return this images pixels as a tensor.\n",
      " |  \n",
      " |  device\n",
      " |  \n",
      " |  flow\n",
      " |      Access the flow-field grid after applying queued affine transforms.\n",
      " |  \n",
      " |  logit_px\n",
      " |      Get logit(image.px).\n",
      " |  \n",
      " |  px\n",
      " |      Get the tensor pixel buffer.\n",
      " |  \n",
      " |  shape\n",
      " |  \n",
      " |  size\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from fastai.core.ItemBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class type in module builtins:\n",
      "\n",
      "class type(object)\n",
      " |  type(object_or_name, bases, dict)\n",
      " |  type(object) -> the object's type\n",
      " |  type(name, bases, dict) -> a new type\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, /, *args, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name, /)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(...)\n",
      " |      __dir__() -> list\n",
      " |      specialized __dir__ implementation for types\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __instancecheck__(...)\n",
      " |      __instancecheck__() -> bool\n",
      " |      check if an object is an instance\n",
      " |  \n",
      " |  __new__(*args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __prepare__(...)\n",
      " |      __prepare__() -> dict\n",
      " |      used to create the namespace for the class statement\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value, /)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      __sizeof__() -> int\n",
      " |      return memory consumption of the type object\n",
      " |  \n",
      " |  __subclasscheck__(...)\n",
      " |      __subclasscheck__() -> bool\n",
      " |      check if a class is a subclass\n",
      " |  \n",
      " |  __subclasses__(...)\n",
      " |      __subclasses__() -> list of immediate subclasses\n",
      " |  \n",
      " |  mro(...)\n",
      " |      mro() -> list\n",
      " |      return a type's method resolution order\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __abstractmethods__\n",
      " |  \n",
      " |  __dict__\n",
      " |  \n",
      " |  __text_signature__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __base__ = <class 'object'>\n",
      " |      The most base type\n",
      " |  \n",
      " |  __bases__ = (<class 'object'>,)\n",
      " |  \n",
      " |  __basicsize__ = 864\n",
      " |  \n",
      " |  __dictoffset__ = 264\n",
      " |  \n",
      " |  __flags__ = 2148291584\n",
      " |  \n",
      " |  __itemsize__ = 40\n",
      " |  \n",
      " |  __mro__ = (<class 'type'>, <class 'object'>)\n",
      " |  \n",
      " |  __weakrefoffset__ = 368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(type(Image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
